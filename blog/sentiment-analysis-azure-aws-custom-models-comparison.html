<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">Sentiment Analysis - Comparing Azure, AWS, and Custom Fine-Tuned Models | Jon Roosevelt</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://jonroosevelt.com/blog/sentiment-analysis-azure-aws-custom-models-comparison"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Sentiment Analysis - Comparing Azure, AWS, and Custom Fine-Tuned Models | Jon Roosevelt"><meta data-rh="true" name="description" content="A comprehensive comparison of sentiment analysis capabilities across Azure Cognitive Text Analytics, AWS Comprehend, and custom fine-tuned models like RoBERTa and Phi2."><meta data-rh="true" property="og:description" content="A comprehensive comparison of sentiment analysis capabilities across Azure Cognitive Text Analytics, AWS Comprehend, and custom fine-tuned models like RoBERTa and Phi2."><meta data-rh="true" property="og:image" content="https://jonroosevelt.com/img/blog/sentiment-analysis-azure-aws-custom-models-comparison/header.png"><meta data-rh="true" name="twitter:image" content="https://jonroosevelt.com/img/blog/sentiment-analysis-azure-aws-custom-models-comparison/header.png"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2024-11-15T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://jonroosevelt.com"><meta data-rh="true" property="article:tag" content="Sentiment Analysis,Azure,AWS,NLP,Machine Learning,Fine-tuning,Model Comparison"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://jonroosevelt.com/blog/sentiment-analysis-azure-aws-custom-models-comparison"><link data-rh="true" rel="alternate" href="https://jonroosevelt.com/blog/sentiment-analysis-azure-aws-custom-models-comparison" hreflang="en"><link data-rh="true" rel="alternate" href="https://jonroosevelt.com/blog/sentiment-analysis-azure-aws-custom-models-comparison" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","@id":"https://jonroosevelt.com/blog/sentiment-analysis-azure-aws-custom-models-comparison","mainEntityOfPage":"https://jonroosevelt.com/blog/sentiment-analysis-azure-aws-custom-models-comparison","url":"https://jonroosevelt.com/blog/sentiment-analysis-azure-aws-custom-models-comparison","headline":"Sentiment Analysis - Comparing Azure, AWS, and Custom Fine-Tuned Models","name":"Sentiment Analysis - Comparing Azure, AWS, and Custom Fine-Tuned Models","description":"A comprehensive comparison of sentiment analysis capabilities across Azure Cognitive Text Analytics, AWS Comprehend, and custom fine-tuned models like RoBERTa and Phi2.","datePublished":"2024-11-15T00:00:00.000Z","author":{"@type":"Person","name":"Jon Roosevelt","description":"Consultant","url":"https://jonroosevelt.com","image":"https://github.com/RooseveltAdvisors.png"},"image":{"@type":"ImageObject","@id":"https://jonroosevelt.com/img/blog/sentiment-analysis-azure-aws-custom-models-comparison/header.png","url":"https://jonroosevelt.com/img/blog/sentiment-analysis-azure-aws-custom-models-comparison/header.png","contentUrl":"https://jonroosevelt.com/img/blog/sentiment-analysis-azure-aws-custom-models-comparison/header.png","caption":"title image for the blog post: Sentiment Analysis - Comparing Azure, AWS, and Custom Fine-Tuned Models"},"keywords":[],"isPartOf":{"@type":"Blog","@id":"https://jonroosevelt.com/blog","name":"Blog"}}</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Jon Roosevelt RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Jon Roosevelt Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-TECW05ZKH4"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-TECW05ZKH4",{anonymize_ip:!0})</script>






<script src="https://cloud.umami.is/script.js" data-website-id="c31542ec-5010-4c26-9acb-391b1c521728" data-domains="jonroosevelt.com,rooseveltadvisors.github.io" defer="defer"></script><link rel="stylesheet" href="/assets/css/styles.e4cadd58.css">
<script src="/assets/js/runtime~main.a3698d86.js" defer="defer"></script>
<script src="/assets/js/main.e836558c.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"dark")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/logo.svg"><link rel="preload" as="image" href="https://github.com/RooseveltAdvisors.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Jon Roosevelt</b></a><a href="https://cloud.umami.is/share/nl5j9KUNu01VtqfG/jonroosevelt.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Analytics</a><a class="navbar__item navbar__link" href="/showcase">Projects</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://www.linkedin.com/in/jonroosevelt/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-linkedin-link" aria-label="Linkedin profile"></a><a href="https://github.com/RooseveltAdvisors" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite" aria-pressed="true"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><div role="group"><h3 class="yearGroupHeading_rMGB">2026</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/2026/01/25/ai-second-brain">How AI Transformed My Second Brain from Passive to Active</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/burden-of-being">The Burden of Being: Why Responsibility Might Be the Antidote to Modern Nihilism</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/ai-urgent-care-trends">Two AI Trends Transforming Urgent Care in 2026</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/four-line-architecture-beat-complex-ai-frameworks">The 4-Line Architecture That Beat Complex AI Frameworks</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/ai-patient-chatbot-urgent-care">Building an AI Patient Chatbot for Urgent Care with n8n, GPT-4, and Langfuse</a></li></ul></div></nav></aside><main class="col col--7"><article class=""><header><h1 class="title_f1Hy">Sentiment Analysis - Comparing Azure, AWS, and Custom Fine-Tuned Models</h1><div class="container_mt6G margin-vert--md"><time datetime="2024-11-15T00:00:00.000Z">November 15, 2024</time> · <!-- -->9 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a class="avatar__photo-link" href="/blog/authors/all-jon-roosevelt-articles"><img class="avatar__photo authorImage_XqGP" src="https://github.com/RooseveltAdvisors.png" alt="Jon Roosevelt"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="/blog/authors/all-jon-roosevelt-articles"><span class="authorName_yefp">Jon Roosevelt</span></a></div><small class="authorTitle_nd0D" title="Consultant">Consultant</small><div class="authorSocials_rSDt"><a href="https://www.linkedin.com/in/jonroosevelt/" target="_blank" rel="noopener noreferrer" class="authorSocialLink_owbf" title="LinkedIn"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" preserveAspectRatio="xMidYMid" viewBox="0 0 256 256" class="authorSocialLink_owbf"><path d="M218.123 218.127h-37.931v-59.403c0-14.165-.253-32.4-19.728-32.4-19.756 0-22.779 15.434-22.779 31.369v60.43h-37.93V95.967h36.413v16.694h.51a39.907 39.907 0 0 1 35.928-19.733c38.445 0 45.533 25.288 45.533 58.186l-.016 67.013ZM56.955 79.27c-12.157.002-22.014-9.852-22.016-22.009-.002-12.157 9.851-22.014 22.008-22.016 12.157-.003 22.014 9.851 22.016 22.008A22.013 22.013 0 0 1 56.955 79.27m18.966 138.858H37.95V95.967h37.97v122.16ZM237.033.018H18.89C8.58-.098.125 8.161-.001 18.471v219.053c.122 10.315 8.576 18.582 18.89 18.474h218.144c10.336.128 18.823-8.139 18.966-18.474V18.454c-.147-10.33-8.635-18.588-18.966-18.453" fill="#0A66C2"></path></svg></a><a href="https://github.com/RooseveltAdvisors" target="_blank" rel="noopener noreferrer" class="authorSocialLink_owbf" title="GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 256 250" preserveAspectRatio="xMidYMid" style="--dark:#000;--light:#fff" class="authorSocialLink_owbf githubSvg_Uu4N"><path d="M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46 6.397 1.185 8.746-2.777 8.746-6.158 0-3.052-.12-13.135-.174-23.83-35.61 7.742-43.124-15.103-43.124-15.103-5.823-14.795-14.213-18.73-14.213-18.73-11.613-7.944.876-7.78.876-7.78 12.853.902 19.621 13.19 19.621 13.19 11.417 19.568 29.945 13.911 37.249 10.64 1.149-8.272 4.466-13.92 8.127-17.116-28.431-3.236-58.318-14.212-58.318-63.258 0-13.975 5-25.394 13.188-34.358-1.329-3.224-5.71-16.242 1.24-33.874 0 0 10.749-3.44 35.21 13.121 10.21-2.836 21.16-4.258 32.038-4.307 10.878.049 21.837 1.47 32.066 4.307 24.431-16.56 35.165-13.12 35.165-13.12 6.967 17.63 2.584 30.65 1.255 33.873 8.207 8.964 13.173 20.383 13.173 34.358 0 49.163-29.944 59.988-58.447 63.157 4.591 3.972 8.682 11.762 8.682 23.704 0 17.126-.148 30.91-.148 35.126 0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002 256 57.307 198.691 0 128.001 0Zm-80.06 182.34c-.282.636-1.283.827-2.194.39-.929-.417-1.45-1.284-1.15-1.922.276-.655 1.279-.838 2.205-.399.93.418 1.46 1.293 1.139 1.931Zm6.296 5.618c-.61.566-1.804.303-2.614-.591-.837-.892-.994-2.086-.375-2.66.63-.566 1.787-.301 2.626.591.838.903 1 2.088.363 2.66Zm4.32 7.188c-.785.545-2.067.034-2.86-1.104-.784-1.138-.784-2.503.017-3.05.795-.547 2.058-.055 2.861 1.075.782 1.157.782 2.522-.019 3.08Zm7.304 8.325c-.701.774-2.196.566-3.29-.49-1.119-1.032-1.43-2.496-.726-3.27.71-.776 2.213-.558 3.315.49 1.11 1.03 1.45 2.505.701 3.27Zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033-1.448-.439-2.395-1.613-2.103-2.626.301-1.01 1.747-1.484 3.207-1.028 1.446.436 2.396 1.602 2.095 2.622Zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95-1.53.034-2.769-.82-2.786-1.86 0-1.065 1.202-1.932 2.733-1.958 1.522-.03 2.768.818 2.768 1.868Zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37-1.485.271-2.861-.365-3.05-1.386-.184-1.056.893-2.114 2.376-2.387 1.514-.263 2.868.356 3.061 1.403Z"></path></svg></a></div></div></div></div></div></header><div id="__blog-post-container" class="markdown"><p>A comprehensive comparison of sentiment analysis capabilities across Azure Cognitive Text Analytics, AWS Comprehend, and custom fine-tuned models like RoBERTa and Phi2.</p>
<p><img decoding="async" loading="lazy" alt="Sentiment Analysis Comparison" src="/assets/images/header-98e52d5c5ce8d541bc245bae92b8a183.png" width="2752" height="1536" class="img_ev3q"></p>
<!-- -->
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-introduction">1. Introduction<a href="#1-introduction" class="hash-link" aria-label="Direct link to 1. Introduction" title="Direct link to 1. Introduction">​</a></h2>
<p>This blog post explores the sentiment analysis capabilities of Azure Cognitive Text Analytics, AWS Comprehend, and custom fine-tuned models like RoBERTa and Phi2 2.7B.</p>
<p>The analysis strongly suggests encouraging my clients to prefer using custom Transformer models or LLMs for sentiment analysis. These models, particularly when fine-tuned, demonstrate superior accuracy and consistency. Fine-tuning is feasible with as few as 20,000 training examples, allowing for tailored solutions that align closely with specific data needs. This approach not only enhances performance but also provides flexibility and precision in sentiment classification, making it a valuable investment for more accurate insights.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-framework-for-evaluation">2. Framework for Evaluation<a href="#2-framework-for-evaluation" class="hash-link" aria-label="Direct link to 2. Framework for Evaluation" title="Direct link to 2. Framework for Evaluation">​</a></h2>
<p>My evaluation framework highlights three key aspects:</p>
<ol>
<li>
<p><strong>Accuracy</strong>: Assessed through F1 Scores, this measures how precisely each model categorizes sentiments, reflecting their effectiveness in sentiment detection.</p>
</li>
<li>
<p><strong>Dependability</strong>: Evaluated via Agreement Analysis, this examines the consistency of predictions across different models, indicating the reliability of their classifications.</p>
</li>
<li>
<p><strong>Potential Bias</strong>: Analyzed through Sentiment Distribution Profiles, this identifies any biases by comparing model outputs to the ground truth, ensuring balanced sentiment representation.</p>
</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-data">3. Data<a href="#3-data" class="hash-link" aria-label="Direct link to 3. Data" title="Direct link to 3. Data">​</a></h2>
<p>To assess these aspects, I used a novel dataset specifically designed for aspect-based sentiment analysis in teacher performance evaluation. This dataset was created by collecting student feedback from American International University-Bangladesh and was labeled by undergraduate-level students into three sentiment classes: positive, negative, and neutral. After cleaning and preprocessing to ensure data quality and consistency, the final dataset contains over 2,000,000 student feedback instances related to teacher performance. This dataset is invaluable for developing and evaluating ABSA models for teacher performance evaluation. <a href="https://data.mendeley.com/datasets/b2yhc95rnx/1" target="_blank" rel="noopener noreferrer">Link: Dataset: A Novel Dataset for Aspect-based Sentiment Analysis for Teacher Performance Evaluation</a></p>
<p>The dataset consists of student feedback on faculty performance, featuring several key columns:</p>
<ul>
<li><strong>StudentComments</strong>: Contains textual feedback from students.</li>
<li><strong>Rating</strong>: A numerical score reflecting the student&#x27;s overall rating of the faculty. (Not used in my analysis)</li>
<li><strong>totalwords</strong>: Indicates the word count of each comment.</li>
<li><strong>Sentiment</strong>: Labels the sentiment as positive, negative, or neutral.</li>
<li><strong>sent_pretrained</strong>: Shows sentiment predictions from a pretrained model. (Not used in my analysis)</li>
<li><strong>subjectivity</strong>: Classifies the comment as subjective or objective. (Not used in my analysis)</li>
<li><strong>subj-score</strong>: Provides a score indicating the degree of subjectivity. (Not used in my analysis)</li>
<li><strong>isSame</strong>: A boolean indicating if the sentiment matches between manual and pretrained labels. (Not used in my analysis)</li>
<li><strong>labels</strong>: Encodes sentiment into numerical labels for analysis.</li>
</ul>
<p>Figure 1 shows a snapshot of my training data. The &quot;StudentComments&quot; column contains the free-form text, while the &quot;Sentiment&quot; column shows the labels. I&#x27;ve only included entries where student comments exceed 200 characters. In total, my dataset has 22,719 records, as shown in Figure 2.</p>
<p><img decoding="async" loading="lazy" alt="Dataset preview" src="/assets/images/dataset-preview-dddb81db2e7fcd4a7b0033632f81307d.png" width="2752" height="1536" class="img_ev3q"></p>
<p><em>Figure-1: Dataset preview</em></p>
<p><img decoding="async" loading="lazy" alt="Dataset summary" src="/assets/images/dataset-summary-2327b4914b971a0f20eb1e4e8247253c.png" width="2752" height="1536" class="img_ev3q"></p>
<p><em>Figure-2: Dataset summary</em></p>
<p>This box plot (Figure-3) illustrates the distribution of ratings across different sentiment categories: positive, neutral, and negative.</p>
<ul>
<li><strong>Positive Sentiment</strong>: Ratings are generally high, clustering around 5, indicating that positive comments correlate with high ratings.</li>
<li><strong>Neutral Sentiment</strong>: Ratings are more centered, with a tighter range around the mid-point, reflecting moderate feedback.</li>
<li><strong>Negative Sentiment</strong>: Ratings are lower, with a wider spread and outliers, showing that negative comments are associated with lower ratings.</li>
</ul>
<p><img decoding="async" loading="lazy" alt="Relationship between Rating and Sentiment" src="/assets/images/rating-sentiment-331727338639a27af54ea164df936bd4.png" width="2752" height="1536" class="img_ev3q"></p>
<p><em>Figure-3: Relationship between Rating and Sentiment</em></p>
<p>The scatter plot (Figure-4) shows the relationship between the number of words in a comment and its rating, categorized by sentiment (positive, neutral, negative).</p>
<ul>
<li><strong>Positive Sentiment (Blue)</strong>: Tends to have higher ratings regardless of comment length.</li>
<li><strong>Neutral Sentiment (Red)</strong>: Ratings are mostly centered around the middle, with varying comment lengths.</li>
<li><strong>Negative Sentiment (Green)</strong>: Generally associated with lower ratings, with some longer comments.</li>
</ul>
<p><img decoding="async" loading="lazy" alt="Rating vs. Total Words with Sentiment" src="/assets/images/rating-vs-words-6ee3d03b4c698ed504870f31b60efd0a.png" width="2752" height="1536" class="img_ev3q"></p>
<p><em>Figure-4: Rating vs. Total Words with Sentiment</em></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-models">4. Models<a href="#4-models" class="hash-link" aria-label="Direct link to 4. Models" title="Direct link to 4. Models">​</a></h2>
<p>Next, let&#x27;s talk about the models/services I&#x27;ve selected for my analysis:</p>
<p><strong>Azure Cognitive Text Analytics</strong></p>
<p>Azure Cognitive Text Analytics offers a sentiment analysis service that evaluates text and returns sentiment scores and labels for each sentence. It is particularly effective in scenarios such as social media monitoring, customer reviews, and discussion forums. Azure&#x27;s model is known for its integration capabilities with other Microsoft services, making it a convenient choice for businesses already using Azure&#x27;s ecosystem.</p>
<p><strong>AWS Comprehend</strong></p>
<p>AWS Comprehend provides a comprehensive natural language processing service that includes sentiment analysis. It is designed to handle large volumes of text with reasonable accuracy, making it suitable for enterprises with significant data processing needs. AWS&#x27;s service is also scalable, allowing businesses to adjust their usage based on demand.</p>
<p><strong>Custom Fine-Tuned Models</strong></p>
<p>In addition to these standard API services, custom fine-tuned models like RoBERTa and Open source Large Language Models (LLM) offer a tailored approach to sentiment analysis. By fine-tuning these models on specific datasets, businesses can achieve higher accuracy and relevance in sentiment detection than standard API services. In this analysis, I&#x27;ve selected RoBERTa and Ph2 2.7B LLM.</p>
<p><strong>Phi2</strong></p>
<p>I used the <a href="https://huggingface.co/microsoft/phi-2" target="_blank" rel="noopener noreferrer">microsoft/phi-2</a> model, a Transformer with 2.7 billion parameters. It was trained using the same data sources as Phi-1.5, augmented with a new data source consisting of various NLP synthetic texts and filtered websites for safety and educational value. Phi-2 demonstrated nearly state-of-the-art performance among models with less than 13 billion parameters in benchmarks testing common sense, language understanding, and logical reasoning. This version of Phi2 has not been fine-tuned through reinforcement learning from human feedback, aiming to provide the research community with a non-restricted small model to explore vital safety challenges, such as reducing toxicity, understanding societal biases, enhancing controllability, and more.</p>
<p><strong>RoBERTa</strong></p>
<p>For this experiment, I used the <a href="https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest" target="_blank" rel="noopener noreferrer">cardiffnlp/twitter-roberta-base-sentiment-latest</a> model, a RoBERTa-base model trained on approximately 124 million tweets from January 2018 to December 2021. It was fine-tuned for sentiment analysis using the TweetEval benchmark, which explains its better performance even before additional fine-tuning compared to Phi2. The original Twitter-based RoBERTa model can be found <a href="https://huggingface.co/cardiffnlp/twitter-roberta-base-2021-124m" target="_blank" rel="noopener noreferrer">here</a>, and the original reference paper is <a href="https://github.com/cardiffnlp/tweeteval" target="_blank" rel="noopener noreferrer">TweetEval</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="5-experiment-results">5. Experiment Results<a href="#5-experiment-results" class="hash-link" aria-label="Direct link to 5. Experiment Results" title="Direct link to 5. Experiment Results">​</a></h2>
<p>In this section, I present the experiment results from three perspectives to comprehensively evaluate the performance of various sentiment analysis models. First, the <strong>Sentiment Distribution Profile</strong> assesses potential biases by comparing how each model classifies sentiment against the ground truth. Second, I analyze <strong>F1 Scores</strong> to measure the accuracy and recall, providing a clear picture of each model&#x27;s effectiveness in sentiment detection. Lastly, the <strong>Agreement Analysis</strong> examines the consistency of predictions across different models, highlighting the level of alignment and reliability in their sentiment classifications. These analyses collectively offer a detailed understanding of model performance and guide the selection of optimal sentiment analysis tools.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="sentiment-distribution-profile">Sentiment Distribution Profile<a href="#sentiment-distribution-profile" class="hash-link" aria-label="Direct link to Sentiment Distribution Profile" title="Direct link to Sentiment Distribution Profile">​</a></h3>
<p>The sentiment distribution graphs provide valuable insights into how different models classify sentiment compared to the ground truth:</p>
<ol>
<li>
<p><strong>Ground Truth</strong>: Represents the distribution of sentiment labels in my dataset, serving as the benchmark for comparison.</p>
</li>
<li>
<p><strong>Azure Sentiment</strong>: Azure tends to classify more feedback as positive and mixed, with fewer neutral sentiments, showing a significant deviation from the ground truth.</p>
</li>
<li>
<p><strong>AWS Sentiment</strong>: Similar to Azure, AWS has a high count of positive sentiments and overestimates mixed sentiments compared to the ground truth.</p>
</li>
<li>
<p><strong>RoBERTa Sentiment</strong>: The pre-trained RoBERTa model aligns more closely with the ground truth for positive sentiments but underestimates neutral feedback. Its superior performance compared to the unfine-tuned Phi2 is due to prior fine-tuning on a Twitter sentiment dataset.</p>
</li>
<li>
<p><strong>Fine-tuned RoBERTa Sentiment</strong>: Fine-tuning enhances RoBERTa&#x27;s alignment with the ground truth, particularly for positive sentiments, though it still underestimates neutral feedback.</p>
</li>
<li>
<p><strong>Phi2 Sentiment</strong>: The unfine-tuned Phi2 model significantly underperforms compared to others, struggling to accurately predict most data points, resulting in minimal representation in the chart.</p>
</li>
<li>
<p><strong>Fine-tuned Phi2 Sentiment</strong>: Fine-tuned Phi2 closely matches the ground truth, demonstrating substantial improvement.</p>
</li>
</ol>
<p>Both fine-tuned models (RoBERTa and Phi2) show enhanced alignment with the ground truth, with fine-tuned Phi2 performing the best. Its improvement over fine-tuned RoBERTa is incremental but noteworthy.</p>
<p><img decoding="async" loading="lazy" alt="Sentiment Distribution" src="/assets/images/sentiment-distribution-434b1fbdcbbf70d63519f1e79a7572f4.png" width="2752" height="1536" class="img_ev3q"></p>
<p><em>Figure-6: Sentiment Distribution</em></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="f1-scores">F1 Scores<a href="#f1-scores" class="hash-link" aria-label="Direct link to F1 Scores" title="Direct link to F1 Scores">​</a></h3>
<p>While Azure and AWS APIs provide an accessible starting point for building sentiment analysis applications, they significantly fall short in accuracy and F1 score for specific use cases compared to fine-tuned models. Custom models like RoBERTa and Phi2 LLM, when properly fine-tuned, deliver superior performance tailored to specific needs.</p>
<p><strong>Figure-7</strong> below illustrates the F1 scores for each model. AWS serves as the benchmark, with other models compared against it to determine percentage improvements. The F1 score ranges from 0 to 1, with 1 being perfect. As a rule of thumb, models with an F1 score above 85% are considered suitable for production deployment.</p>
<p><img decoding="async" loading="lazy" alt="F1 Scores" src="/assets/images/f1-scores-561e0b0b388253f1c91c250f3bd95a91.png" width="2752" height="1536" class="img_ev3q"></p>
<p><em>Figure-7: F1 Scores</em></p>
<p>Fine-tuned models, particularly Fine-tuned Phi2, significantly outperform both AWS and Azure in accuracy, precision, recall, and F1 score. While AWS and Azure offer convenient and scalable solutions, custom fine-tuning of models like RoBERTa and Phi2 provides a more tailored and accurate approach for specific use cases.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pairwise-agreement-analysis">Pairwise Agreement Analysis<a href="#pairwise-agreement-analysis" class="hash-link" aria-label="Direct link to Pairwise Agreement Analysis" title="Direct link to Pairwise Agreement Analysis">​</a></h3>
<p>The highest agreement is between Fine-tuned RoBERTa and Fine-tuned Phi2 at 90.84%, indicating strong consistency between these two fine-tuned models.</p>
<p>Fine-tuned models tend to agree more with each other, demonstrating the effectiveness of fine-tuning in aligning sentiment predictions. In contrast, Azure and Phi2 show low agreement, highlighting variability in their sentiment analysis approaches.</p>
<p><img decoding="async" loading="lazy" alt="Pairwise agreement analysis" src="/assets/images/pairwise-agreement-6bf1ab9a5e7a1cdba4bb4f671f096e98.png" width="2752" height="1536" class="img_ev3q"></p>
<p><em>Figure-8: Pairwise agreement analysis</em></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="6-summary">6. Summary<a href="#6-summary" class="hash-link" aria-label="Direct link to 6. Summary" title="Direct link to 6. Summary">​</a></h2>
<p>The analysis strongly suggests encouraging my clients to prefer using custom Transformer models or LLMs for sentiment analysis. These models, particularly when fine-tuned, demonstrate superior accuracy and consistency. Fine-tuning is feasible with as few as 20,000 training examples, allowing for tailored solutions that align closely with specific data needs. This approach not only enhances performance but also provides flexibility and precision in sentiment classification, making it a valuable investment for more accurate insights.</p>
<p>For those aiming to maximize F1 scores, building a custom model is the optimal path forward. In the next part of this series, I&#x27;ll explore how to fine-tune these models to better meet your specific requirements (<a href="/blog/fine-tuning-microsoft-phi-2-for-sentiment-analysis">link here</a>).</p></div><footer class="docusaurus-mt-lg"><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a title="Content about analyzing and classifying sentiment in text" class="tag_zVej tagRegular_sFm0" href="/blog/tags/tags/sentiment-analysis">Sentiment Analysis</a></li><li class="tag_QGVx"><a title="Microsoft Azure cloud platform and services" class="tag_zVej tagRegular_sFm0" href="/blog/tags/tags/azure">Azure</a></li><li class="tag_QGVx"><a title="Content related to Amazon Web Services and its offerings" class="tag_zVej tagRegular_sFm0" href="/blog/tags/tags/aws">AWS</a></li><li class="tag_QGVx"><a title="Natural Language Processing techniques and applications" class="tag_zVej tagRegular_sFm0" href="/blog/tags/tags/nlp">NLP</a></li><li class="tag_QGVx"><a title="Topics covering machine learning algorithms and applications" class="tag_zVej tagRegular_sFm0" href="/blog/tags/tags/machine-learning">Machine Learning</a></li><li class="tag_QGVx"><a title="Articles about fine-tuning and adapting language models" class="tag_zVej tagRegular_sFm0" href="/blog/tags/tags/fine-tuning">Fine-tuning</a></li><li class="tag_QGVx"><a title="Articles comparing different AI models, approaches, or implementations" class="tag_zVej tagRegular_sFm0" href="/blog/tags/tags/model-comparison">Model Comparison</a></li></ul></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/blog/handling-skewed-data-in-apache-spark-performance-optimization"><div class="pagination-nav__sublabel">Newer post</div><div class="pagination-nav__label">Optimizing Apache Spark Performance for Skewed Data - Advanced Techniques and Case Study</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#1-introduction" class="table-of-contents__link toc-highlight">1. Introduction</a></li><li><a href="#2-framework-for-evaluation" class="table-of-contents__link toc-highlight">2. Framework for Evaluation</a></li><li><a href="#3-data" class="table-of-contents__link toc-highlight">3. Data</a></li><li><a href="#4-models" class="table-of-contents__link toc-highlight">4. Models</a></li><li><a href="#5-experiment-results" class="table-of-contents__link toc-highlight">5. Experiment Results</a><ul><li><a href="#sentiment-distribution-profile" class="table-of-contents__link toc-highlight">Sentiment Distribution Profile</a></li><li><a href="#f1-scores" class="table-of-contents__link toc-highlight">F1 Scores</a></li><li><a href="#pairwise-agreement-analysis" class="table-of-contents__link toc-highlight">Pairwise Agreement Analysis</a></li></ul></li><li><a href="#6-summary" class="table-of-contents__link toc-highlight">6. Summary</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Connect</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.linkedin.com/in/jonroosevelt/" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 Jon Roosevelt, Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>