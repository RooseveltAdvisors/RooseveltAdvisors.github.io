<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">Accelerating Document Intelligence - A Deep Dive into GPU-Powered RAG Processing | Jon Roosevelt</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://jonroosevelt.com/blog/gpu-accelerated-rag"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Accelerating Document Intelligence - A Deep Dive into GPU-Powered RAG Processing | Jon Roosevelt"><meta data-rh="true" name="description" content="Learn how to leverage GPU acceleration to significantly improve document processing speed in Retrieval-Augmented Generation (RAG) systems."><meta data-rh="true" property="og:description" content="Learn how to leverage GPU acceleration to significantly improve document processing speed in Retrieval-Augmented Generation (RAG) systems."><meta data-rh="true" property="og:image" content="https://jonroosevelt.com/img/blog/2025-03-13-gpu-rag-processing/gpu-rag-header.jpg"><meta data-rh="true" name="twitter:image" content="https://jonroosevelt.com/img/blog/2025-03-13-gpu-rag-processing/gpu-rag-header.jpg"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2025-03-13T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://jonroosevelt.com"><meta data-rh="true" property="article:tag" content="RAG,GPU Acceleration,Document Processing,Performance Optimization,AI"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://jonroosevelt.com/blog/gpu-accelerated-rag"><link data-rh="true" rel="alternate" href="https://jonroosevelt.com/blog/gpu-accelerated-rag" hreflang="en"><link data-rh="true" rel="alternate" href="https://jonroosevelt.com/blog/gpu-accelerated-rag" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","@id":"https://jonroosevelt.com/blog/gpu-accelerated-rag","mainEntityOfPage":"https://jonroosevelt.com/blog/gpu-accelerated-rag","url":"https://jonroosevelt.com/blog/gpu-accelerated-rag","headline":"Accelerating Document Intelligence - A Deep Dive into GPU-Powered RAG Processing","name":"Accelerating Document Intelligence - A Deep Dive into GPU-Powered RAG Processing","description":"Learn how to leverage GPU acceleration to significantly improve document processing speed in Retrieval-Augmented Generation (RAG) systems.","datePublished":"2025-03-13T00:00:00.000Z","author":{"@type":"Person","name":"Jon Roosevelt","description":"Consultant","url":"https://jonroosevelt.com","image":"https://github.com/RooseveltAdvisors.png"},"image":{"@type":"ImageObject","@id":"https://jonroosevelt.com/img/blog/2025-03-13-gpu-rag-processing/gpu-rag-header.jpg","url":"https://jonroosevelt.com/img/blog/2025-03-13-gpu-rag-processing/gpu-rag-header.jpg","contentUrl":"https://jonroosevelt.com/img/blog/2025-03-13-gpu-rag-processing/gpu-rag-header.jpg","caption":"title image for the blog post: Accelerating Document Intelligence - A Deep Dive into GPU-Powered RAG Processing"},"keywords":[],"isPartOf":{"@type":"Blog","@id":"https://jonroosevelt.com/blog","name":"Blog"}}</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Jon Roosevelt RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Jon Roosevelt Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-TECW05ZKH4"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-TECW05ZKH4",{anonymize_ip:!0})</script>






<script src="https://cloud.umami.is/script.js" data-website-id="c31542ec-5010-4c26-9acb-391b1c521728" data-domains="jonroosevelt.com,rooseveltadvisors.github.io" defer="defer"></script><link rel="stylesheet" href="/assets/css/styles.e4cadd58.css">
<script src="/assets/js/runtime~main.a3698d86.js" defer="defer"></script>
<script src="/assets/js/main.e836558c.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"dark")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/logo.svg"><link rel="preload" as="image" href="https://github.com/RooseveltAdvisors.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Jon Roosevelt</b></a><a href="https://cloud.umami.is/share/nl5j9KUNu01VtqfG/jonroosevelt.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Analytics</a><a class="navbar__item navbar__link" href="/showcase">Projects</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://www.linkedin.com/in/jonroosevelt/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-linkedin-link" aria-label="Linkedin profile"></a><a href="https://github.com/RooseveltAdvisors" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite" aria-pressed="true"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><div role="group"><h3 class="yearGroupHeading_rMGB">2026</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/2026/01/25/ai-second-brain">How AI Transformed My Second Brain from Passive to Active</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/burden-of-being">The Burden of Being: Why Responsibility Might Be the Antidote to Modern Nihilism</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/ai-urgent-care-trends">Two AI Trends Transforming Urgent Care in 2026</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/four-line-architecture-beat-complex-ai-frameworks">The 4-Line Architecture That Beat Complex AI Frameworks</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/ai-patient-chatbot-urgent-care">Building an AI Patient Chatbot for Urgent Care with n8n, GPT-4, and Langfuse</a></li></ul></div></nav></aside><main class="col col--7"><article class=""><header><h1 class="title_f1Hy">Accelerating Document Intelligence - A Deep Dive into GPU-Powered RAG Processing</h1><div class="container_mt6G margin-vert--md"><time datetime="2025-03-13T00:00:00.000Z">March 13, 2025</time> · <!-- -->6 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a class="avatar__photo-link" href="/blog/authors/all-jon-roosevelt-articles"><img class="avatar__photo authorImage_XqGP" src="https://github.com/RooseveltAdvisors.png" alt="Jon Roosevelt"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="/blog/authors/all-jon-roosevelt-articles"><span class="authorName_yefp">Jon Roosevelt</span></a></div><small class="authorTitle_nd0D" title="Consultant">Consultant</small><div class="authorSocials_rSDt"><a href="https://www.linkedin.com/in/jonroosevelt/" target="_blank" rel="noopener noreferrer" class="authorSocialLink_owbf" title="LinkedIn"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" preserveAspectRatio="xMidYMid" viewBox="0 0 256 256" class="authorSocialLink_owbf"><path d="M218.123 218.127h-37.931v-59.403c0-14.165-.253-32.4-19.728-32.4-19.756 0-22.779 15.434-22.779 31.369v60.43h-37.93V95.967h36.413v16.694h.51a39.907 39.907 0 0 1 35.928-19.733c38.445 0 45.533 25.288 45.533 58.186l-.016 67.013ZM56.955 79.27c-12.157.002-22.014-9.852-22.016-22.009-.002-12.157 9.851-22.014 22.008-22.016 12.157-.003 22.014 9.851 22.016 22.008A22.013 22.013 0 0 1 56.955 79.27m18.966 138.858H37.95V95.967h37.97v122.16ZM237.033.018H18.89C8.58-.098.125 8.161-.001 18.471v219.053c.122 10.315 8.576 18.582 18.89 18.474h218.144c10.336.128 18.823-8.139 18.966-18.474V18.454c-.147-10.33-8.635-18.588-18.966-18.453" fill="#0A66C2"></path></svg></a><a href="https://github.com/RooseveltAdvisors" target="_blank" rel="noopener noreferrer" class="authorSocialLink_owbf" title="GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 256 250" preserveAspectRatio="xMidYMid" style="--dark:#000;--light:#fff" class="authorSocialLink_owbf githubSvg_Uu4N"><path d="M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46 6.397 1.185 8.746-2.777 8.746-6.158 0-3.052-.12-13.135-.174-23.83-35.61 7.742-43.124-15.103-43.124-15.103-5.823-14.795-14.213-18.73-14.213-18.73-11.613-7.944.876-7.78.876-7.78 12.853.902 19.621 13.19 19.621 13.19 11.417 19.568 29.945 13.911 37.249 10.64 1.149-8.272 4.466-13.92 8.127-17.116-28.431-3.236-58.318-14.212-58.318-63.258 0-13.975 5-25.394 13.188-34.358-1.329-3.224-5.71-16.242 1.24-33.874 0 0 10.749-3.44 35.21 13.121 10.21-2.836 21.16-4.258 32.038-4.307 10.878.049 21.837 1.47 32.066 4.307 24.431-16.56 35.165-13.12 35.165-13.12 6.967 17.63 2.584 30.65 1.255 33.873 8.207 8.964 13.173 20.383 13.173 34.358 0 49.163-29.944 59.988-58.447 63.157 4.591 3.972 8.682 11.762 8.682 23.704 0 17.126-.148 30.91-.148 35.126 0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002 256 57.307 198.691 0 128.001 0Zm-80.06 182.34c-.282.636-1.283.827-2.194.39-.929-.417-1.45-1.284-1.15-1.922.276-.655 1.279-.838 2.205-.399.93.418 1.46 1.293 1.139 1.931Zm6.296 5.618c-.61.566-1.804.303-2.614-.591-.837-.892-.994-2.086-.375-2.66.63-.566 1.787-.301 2.626.591.838.903 1 2.088.363 2.66Zm4.32 7.188c-.785.545-2.067.034-2.86-1.104-.784-1.138-.784-2.503.017-3.05.795-.547 2.058-.055 2.861 1.075.782 1.157.782 2.522-.019 3.08Zm7.304 8.325c-.701.774-2.196.566-3.29-.49-1.119-1.032-1.43-2.496-.726-3.27.71-.776 2.213-.558 3.315.49 1.11 1.03 1.45 2.505.701 3.27Zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033-1.448-.439-2.395-1.613-2.103-2.626.301-1.01 1.747-1.484 3.207-1.028 1.446.436 2.396 1.602 2.095 2.622Zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95-1.53.034-2.769-.82-2.786-1.86 0-1.065 1.202-1.932 2.733-1.958 1.522-.03 2.768.818 2.768 1.868Zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37-1.485.271-2.861-.365-3.05-1.386-.184-1.056.893-2.114 2.376-2.387 1.514-.263 2.868.356 3.061 1.403Z"></path></svg></a></div></div></div></div></div></header><div id="__blog-post-container" class="markdown"><p>Learn how to leverage GPU acceleration to significantly improve document processing speed in Retrieval-Augmented Generation (RAG) systems.</p>
<p><img decoding="async" loading="lazy" alt="GPU-Accelerated RAG System" src="/assets/images/gpu-rag-header-1c21fb92639128336f357e335ca9cfd5.png" width="2752" height="1536" class="img_ev3q"></p>
<!-- -->
<p>In the world of enterprise AI and document intelligence, processing speed can be a significant bottleneck. As document collections grow into the thousands or even millions, traditional CPU-based RAG (Retrieval-Augmented Generation) pipelines struggle to keep pace. This article explores how GPU acceleration can transform your document processing workflow, delivering up to 5x faster performance while maintaining or even improving quality.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-document-processing-challenge">The Document Processing Challenge<a href="#the-document-processing-challenge" class="hash-link" aria-label="Direct link to The Document Processing Challenge" title="Direct link to The Document Processing Challenge">​</a></h2>
<p>Before diving into the solution, let&#x27;s understand the problem. A typical RAG pipeline involves several compute-intensive steps:</p>
<ol>
<li><strong>Document Parsing</strong>: Converting various formats (PDF, DOCX, etc.) into machine-readable text</li>
<li><strong>Text Extraction &amp; Cleaning</strong>: Removing noise, handling special characters, normalizing text</li>
<li><strong>Chunking</strong>: Breaking documents into semantically meaningful segments</li>
<li><strong>Embedding Generation</strong>: Converting text chunks into vector representations</li>
<li><strong>Vector Storage</strong>: Indexing and storing these embeddings for retrieval</li>
</ol>
<p>For large document collections, these steps can take hours or even days to complete on CPU-based systems. When document updates are frequent, this latency becomes unacceptable for real-time applications.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-gpu-acceleration-strategy">The GPU Acceleration Strategy<a href="#the-gpu-acceleration-strategy" class="hash-link" aria-label="Direct link to The GPU Acceleration Strategy" title="Direct link to The GPU Acceleration Strategy">​</a></h2>
<p>GPUs (Graphics Processing Units) excel at parallel processing tasks - operations that can be performed simultaneously on multiple data points. Many steps in the RAG pipeline fit this pattern perfectly, especially the embedding generation phase which typically accounts for 60-70% of processing time.</p>
<p>Here&#x27;s how we leveraged GPU acceleration across the entire pipeline:</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-multi-gpu-document-parsing">1. Multi-GPU Document Parsing<a href="#1-multi-gpu-document-parsing" class="hash-link" aria-label="Direct link to 1. Multi-GPU Document Parsing" title="Direct link to 1. Multi-GPU Document Parsing">​</a></h3>
<p>While document parsing might seem like a sequential task, we can parallelize it across multiple GPUs by batching documents:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">process_documents</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">documents</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> available_gpus</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># Distribute documents across available GPUs</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    batches </span><span class="token operator">=</span><span class="token plain"> create_balanced_batches</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">documents</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(189, 147, 249)">len</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">available_gpus</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># Process batches in parallel</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">with</span><span class="token plain"> concurrent</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">futures</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">ThreadPoolExecutor</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">as</span><span class="token plain"> executor</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        futures </span><span class="token operator">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            executor</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">submit</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">process_batch</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> batch</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> gpu_id</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">for</span><span class="token plain"> batch</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> gpu_id </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">in</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(189, 147, 249)">zip</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">batches</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> available_gpus</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        results </span><span class="token operator">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">future</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">result</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">for</span><span class="token plain"> future </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">in</span><span class="token plain"> futures</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">return</span><span class="token plain"> combine_results</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">results</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This approach allows us to process different documents simultaneously on separate GPUs, providing near-linear scaling with the number of available graphics cards.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-smart-batching-for-text-processing">2. Smart Batching for Text Processing<a href="#2-smart-batching-for-text-processing" class="hash-link" aria-label="Direct link to 2. Smart Batching for Text Processing" title="Direct link to 2. Smart Batching for Text Processing">​</a></h3>
<p>When working with GPUs, batch size optimization is crucial. Too small, and you waste GPU capacity; too large, and you risk out-of-memory errors:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">smart_batch_processor</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">texts</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> max_batch_size</span><span class="token operator">=</span><span class="token number">32</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># Group texts by similar lengths to optimize GPU memory usage</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    texts_by_length </span><span class="token operator">=</span><span class="token plain"> group_by_approximate_length</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">texts</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    batches </span><span class="token operator">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">for</span><span class="token plain"> length_group </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">in</span><span class="token plain"> texts_by_length</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token comment" style="color:rgb(98, 114, 164)"># Dynamically adjust batch size based on text length</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        adjusted_batch_size </span><span class="token operator">=</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(189, 147, 249)">min</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            max_batch_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            calculate_optimal_batch_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">length_group</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token number">0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> available_gpu_memory</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token comment" style="color:rgb(98, 114, 164)"># Create batches from this length group</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">for</span><span class="token plain"> i </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">in</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(189, 147, 249)">range</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(189, 147, 249)">len</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">length_group</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> adjusted_batch_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            batches</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">append</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">length_group</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">i</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">i </span><span class="token operator">+</span><span class="token plain"> adjusted_batch_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">return</span><span class="token plain"> batches</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This &quot;length-aware&quot; batching improves GPU utilization by 40-50% compared to naive approaches, especially when document lengths vary significantly.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="3-gpu-accelerated-embedding-generation">3. GPU-Accelerated Embedding Generation<a href="#3-gpu-accelerated-embedding-generation" class="hash-link" aria-label="Direct link to 3. GPU-Accelerated Embedding Generation" title="Direct link to 3. GPU-Accelerated Embedding Generation">​</a></h3>
<p>The most compute-intensive part of the pipeline is embedding generation. Here, GPU acceleration provides dramatic improvements:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">class</span><span class="token plain"> </span><span class="token class-name">GPUEmbeddingGenerator</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">__init__</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> model_name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> device_map</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;auto&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token comment" style="color:rgb(98, 114, 164)"># Load model with automatic GPU distribution</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">model </span><span class="token operator">=</span><span class="token plain"> SentenceTransformer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">model_name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> device</span><span class="token operator">=</span><span class="token plain">device_map</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">generate_embeddings</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> texts</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token comment" style="color:rgb(98, 114, 164)"># Perform embedding generation on GPU</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">return</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">encode</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            texts</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            batch_size</span><span class="token operator">=</span><span class="token number">64</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            show_progress_bar</span><span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            convert_to_tensor</span><span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            normalize_embeddings</span><span class="token operator">=</span><span class="token boolean">True</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>By moving embedding computation to the GPU and optimizing batch sizes, we observed a 4-7x speedup in this phase alone.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="technical-hurdles--solutions">Technical Hurdles &amp; Solutions<a href="#technical-hurdles--solutions" class="hash-link" aria-label="Direct link to Technical Hurdles &amp; Solutions" title="Direct link to Technical Hurdles &amp; Solutions">​</a></h2>
<p>Implementing GPU acceleration for RAG wasn&#x27;t without challenges. Here are the major hurdles we encountered and how we solved them:</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-gpu-memory-management">1. GPU Memory Management<a href="#1-gpu-memory-management" class="hash-link" aria-label="Direct link to 1. GPU Memory Management" title="Direct link to 1. GPU Memory Management">​</a></h3>
<p><strong>Problem</strong>: Large documents would cause out-of-memory errors when processing on GPU.</p>
<p><strong>Solution</strong>: We implemented a memory-aware chunking strategy that dynamically adjusts chunk sizes based on available GPU memory:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">memory_aware_chunking</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">document</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> available_memory</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># Estimate memory requirements</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    estimated_memory_per_token </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">128</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># bytes</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># Calculate maximum chunk size based on available memory</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># Using 80% of available memory as a safety margin</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    safe_memory </span><span class="token operator">=</span><span class="token plain"> available_memory </span><span class="token operator">*</span><span class="token plain"> </span><span class="token number">0.8</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    max_tokens </span><span class="token operator">=</span><span class="token plain"> safe_memory </span><span class="token operator">/</span><span class="token plain"> estimated_memory_per_token</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># Dynamic chunking based on available memory</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">return</span><span class="token plain"> create_chunks</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">document</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> max_tokens</span><span class="token operator">=</span><span class="token plain">max_tokens</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-cuda-version-conflicts">2. CUDA Version Conflicts<a href="#2-cuda-version-conflicts" class="hash-link" aria-label="Direct link to 2. CUDA Version Conflicts" title="Direct link to 2. CUDA Version Conflicts">​</a></h3>
<p><strong>Problem</strong>: Different libraries requiring different CUDA versions.</p>
<p><strong>Solution</strong>: We created a containerized environment with compatible versions of all dependencies:</p>
<div class="language-dockerfile codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-dockerfile codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Install Python</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">RUN apt-get update &amp;&amp; apt-get install -y python3-pip</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Install compatible versions of PyTorch and related libraries</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">RUN pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 --extra-index-url https://download.pytorch.org/whl/cu118</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Install other dependencies</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">RUN pip install transformers==4.31.0 sentence-transformers==2.2.2</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="3-processing-pipeline-integrity">3. Processing Pipeline Integrity<a href="#3-processing-pipeline-integrity" class="hash-link" aria-label="Direct link to 3. Processing Pipeline Integrity" title="Direct link to 3. Processing Pipeline Integrity">​</a></h3>
<p><strong>Problem</strong>: GPU acceleration sometimes led to processing errors or incomplete results.</p>
<p><strong>Solution</strong>: We implemented a robust checkpoint and verification system:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">process_with_verification</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">documents</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    results </span><span class="token operator">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    failed </span><span class="token operator">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">for</span><span class="token plain"> doc </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">in</span><span class="token plain"> documents</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">try</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token comment" style="color:rgb(98, 114, 164)"># Process with timeout to prevent GPU hangs</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">with</span><span class="token plain"> timeout</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">seconds</span><span class="token operator">=</span><span class="token number">300</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                result </span><span class="token operator">=</span><span class="token plain"> gpu_process_document</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">doc</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token comment" style="color:rgb(98, 114, 164)"># Verify result integrity</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">if</span><span class="token plain"> verify_document_processing</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">doc</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> result</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                results</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">append</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">result</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">else</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                failed</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">append</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">doc</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">except</span><span class="token plain"> Exception </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">as</span><span class="token plain"> e</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            logger</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">error</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">f&quot;Failed to process </span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string-interpolation interpolation">doc</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token string-interpolation interpolation builtin" style="color:rgb(189, 147, 249)">id</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">: </span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string-interpolation interpolation builtin" style="color:rgb(189, 147, 249)">str</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            failed</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">append</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">doc</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># Retry failed documents on CPU if necessary</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">if</span><span class="token plain"> failed</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        cpu_results </span><span class="token operator">=</span><span class="token plain"> cpu_process_documents</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">failed</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        results</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">extend</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">cpu_results</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">return</span><span class="token plain"> results</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance-gains">Performance Gains<a href="#performance-gains" class="hash-link" aria-label="Direct link to Performance Gains" title="Direct link to Performance Gains">​</a></h2>
<p>Our GPU-accelerated approach delivered dramatic performance improvements:</p>
<table><thead><tr><th>Metric</th><th>CPU-Only</th><th>GPU-Accelerated</th><th>Improvement</th></tr></thead><tbody><tr><td>Processing Speed</td><td>10 pages/sec</td><td>50 pages/sec</td><td>5x</td></tr><tr><td>Embedding Generation</td><td>45 min/GB</td><td>8 min/GB</td><td>5.6x</td></tr><tr><td>Total Processing Time</td><td>3.5 hours</td><td>42 minutes</td><td>5x</td></tr><tr><td>Cost per Document</td><td>$0.05</td><td>$0.01</td><td>5x</td></tr></tbody></table>
<p>These improvements scale with document volume, making the approach particularly valuable for enterprise settings with large document collections.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="implementation-considerations">Implementation Considerations<a href="#implementation-considerations" class="hash-link" aria-label="Direct link to Implementation Considerations" title="Direct link to Implementation Considerations">​</a></h2>
<p>If you&#x27;re considering GPU acceleration for your RAG system, here are some practical considerations:</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-hardware-selection">1. Hardware Selection<a href="#1-hardware-selection" class="hash-link" aria-label="Direct link to 1. Hardware Selection" title="Direct link to 1. Hardware Selection">​</a></h3>
<p>Not all GPUs are created equal for RAG workloads:</p>
<ul>
<li><strong>Memory is crucial</strong>: Choose GPUs with at least 16GB VRAM for production workloads</li>
<li><strong>Compute capability</strong>: Ensure your GPUs support the CUDA version required by your libraries</li>
<li><strong>Multi-GPU setup</strong>: Consider multiple smaller GPUs rather than a single large one for better parallelization</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-software-stack-optimization">2. Software Stack Optimization<a href="#2-software-stack-optimization" class="hash-link" aria-label="Direct link to 2. Software Stack Optimization" title="Direct link to 2. Software Stack Optimization">​</a></h3>
<ul>
<li>Use PyTorch with CUDA support for optimal performance</li>
<li>Leverage libraries with built-in GPU support like Hugging Face Transformers and Sentence Transformers</li>
<li>Consider mixed precision (FP16) for further performance gains</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="3-monitoring-and-maintenance">3. Monitoring and Maintenance<a href="#3-monitoring-and-maintenance" class="hash-link" aria-label="Direct link to 3. Monitoring and Maintenance" title="Direct link to 3. Monitoring and Maintenance">​</a></h3>
<ul>
<li>Implement GPU utilization monitoring</li>
<li>Watch for memory leaks</li>
<li>Consider automatic scaling based on workload</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2>
<p>GPU acceleration represents a significant advancement for RAG systems, dramatically reducing processing time while maintaining or improving quality. By carefully architecting your pipeline to leverage parallel processing capabilities, smart batching, and memory-aware execution, you can achieve performance gains of 5x or more.</p>
<p>This approach is particularly valuable in enterprise settings where document volumes are large and processing speed directly impacts user experience and operational efficiency. While implementing GPU acceleration requires careful consideration of hardware, software compatibility, and error handling, the performance benefits make it well worth the investment.</p>
<p>For more details on this implementation, visit our <a href="https://github.com/RooseveltAdvisors/enterprise-rag" target="_blank" rel="noopener noreferrer">GitHub repository</a> where we&#x27;ve shared our approach and key components of our GPU-accelerated RAG system.</p></div><footer class="docusaurus-mt-lg"><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a title="Retrieval Augmented Generation (RAG) techniques and applications" class="tag_zVej tagRegular_sFm0" href="/blog/tags/tags/rag">RAG</a></li><li class="tag_QGVx"><a title="GPU-accelerated computing and processing techniques" class="tag_zVej tagRegular_sFm0" href="/blog/tags/tags/gpu-acceleration">GPU Acceleration</a></li><li class="tag_QGVx"><a title="Processing and analyzing document content" class="tag_zVej tagRegular_sFm0" href="/blog/tags/tags/document-processing">Document Processing</a></li><li class="tag_QGVx"><a title="Techniques for improving system performance" class="tag_zVej tagRegular_sFm0" href="/blog/tags/tags/performance-optimization">Performance Optimization</a></li><li class="tag_QGVx"><a title="Articles about artificial intelligence and machine learning" class="tag_zVej tagRegular_sFm0" href="/blog/tags/tags/ai">AI</a></li></ul></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/blog/semantic-kernel-research-agent"><div class="pagination-nav__sublabel">Newer post</div><div class="pagination-nav__label">Porting GPTResearcher to Semantic Kernel - Building an Enterprise-Ready Research Agent</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/blog/enterprise-rag-system"><div class="pagination-nav__sublabel">Older post</div><div class="pagination-nav__label">Building an Enterprise-Grade RAG System - A Deep Dive into Advanced Document Intelligence</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#the-document-processing-challenge" class="table-of-contents__link toc-highlight">The Document Processing Challenge</a></li><li><a href="#the-gpu-acceleration-strategy" class="table-of-contents__link toc-highlight">The GPU Acceleration Strategy</a><ul><li><a href="#1-multi-gpu-document-parsing" class="table-of-contents__link toc-highlight">1. Multi-GPU Document Parsing</a></li><li><a href="#2-smart-batching-for-text-processing" class="table-of-contents__link toc-highlight">2. Smart Batching for Text Processing</a></li><li><a href="#3-gpu-accelerated-embedding-generation" class="table-of-contents__link toc-highlight">3. GPU-Accelerated Embedding Generation</a></li></ul></li><li><a href="#technical-hurdles--solutions" class="table-of-contents__link toc-highlight">Technical Hurdles &amp; Solutions</a><ul><li><a href="#1-gpu-memory-management" class="table-of-contents__link toc-highlight">1. GPU Memory Management</a></li><li><a href="#2-cuda-version-conflicts" class="table-of-contents__link toc-highlight">2. CUDA Version Conflicts</a></li><li><a href="#3-processing-pipeline-integrity" class="table-of-contents__link toc-highlight">3. Processing Pipeline Integrity</a></li></ul></li><li><a href="#performance-gains" class="table-of-contents__link toc-highlight">Performance Gains</a></li><li><a href="#implementation-considerations" class="table-of-contents__link toc-highlight">Implementation Considerations</a><ul><li><a href="#1-hardware-selection" class="table-of-contents__link toc-highlight">1. Hardware Selection</a></li><li><a href="#2-software-stack-optimization" class="table-of-contents__link toc-highlight">2. Software Stack Optimization</a></li><li><a href="#3-monitoring-and-maintenance" class="table-of-contents__link toc-highlight">3. Monitoring and Maintenance</a></li></ul></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Connect</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.linkedin.com/in/jonroosevelt/" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 Jon Roosevelt, Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>