"use strict";(self.webpackChunkroosevelt_advisors_website=self.webpackChunkroosevelt_advisors_website||[]).push([[2112],{5480:(e,n,r)=>{r.d(n,{A:()=>t});const t=r.p+"assets/images/semantic-kernel-header-669e35174c918ac20f4ff9e4703143d7.png"},26909:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>i,metadata:()=>t,toc:()=>c});var t=r(80445),s=r(74848),a=r(28453);const i={slug:"semantic-kernel-research-agent",title:"Porting GPTResearcher to Semantic Kernel - Building an Enterprise-Ready Research Agent",authors:["jon"],tags:["semantic-kernel","azure-openai","ai-agents","enterprise-ai","llm"],image:"/img/blog/2025-03-20-semantic-kernel-ai-agent/semantic-kernel-header.png"},o="Porting GPTResearcher to Semantic Kernel: Building an Enterprise-Ready Research Agent",l={authorsImageUrls:[void 0]},c=[{value:"Why Port to Semantic Kernel?",id:"why-port-to-semantic-kernel",level:2},{value:"Architecture Overview",id:"architecture-overview",level:2},{value:"Key Components",id:"key-components",level:3},{value:"The Semantic Kernel Integration",id:"the-semantic-kernel-integration",level:2},{value:"1. SemanticKernelManager",id:"1-semantickernelmanager",level:3},{value:"2. JResearcherPlugin",id:"2-jresearcherplugin",level:3},{value:"3. WebSocket Integration",id:"3-websocket-integration",level:3},{value:"Enhanced Capabilities",id:"enhanced-capabilities",level:2},{value:"1. Multiple Research Agents",id:"1-multiple-research-agents",level:3},{value:"2. SEC EDGAR Integration",id:"2-sec-edgar-integration",level:3},{value:"3. Azure AI Evaluation Integration",id:"3-azure-ai-evaluation-integration",level:3},{value:"Technical Challenges and Solutions",id:"technical-challenges-and-solutions",level:2},{value:"1. Asynchronous Processing",id:"1-asynchronous-processing",level:3},{value:"2. Authentication Flow",id:"2-authentication-flow",level:3},{value:"3. Evaluation Challenges",id:"3-evaluation-challenges",level:3},{value:"4. Multi-Agent Framework",id:"4-multi-agent-framework",level:3},{value:"Results and Performance Metrics",id:"results-and-performance-metrics",level:2},{value:"Lessons Learned",id:"lessons-learned",level:2},{value:"Conclusion",id:"conclusion",level:2}];function d(e){const n={code:"code",h2:"h2",h3:"h3",img:"img",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.p,{children:"Learn how to transform an open-source AI research agent into an enterprise-ready solution using Microsoft's Semantic Kernel framework with Azure OpenAI."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Semantic Kernel Research Agent",src:r(5480).A+"",width:"2752",height:"1536"})}),"\n","\n",(0,s.jsx)(n.p,{children:"Enterprise adoption of AI systems often requires integrating open-source innovations with enterprise-grade frameworks that provide security, scalability, and compliance. In this post, I'll detail the process of porting GPTResearcher\u2014a popular open-source AI research agent\u2014to Microsoft's Semantic Kernel framework, enabling seamless integration with Azure OpenAI and enterprise authentication."}),"\n",(0,s.jsx)(n.h2,{id:"why-port-to-semantic-kernel",children:"Why Port to Semantic Kernel?"}),"\n",(0,s.jsx)(n.p,{children:"GPTResearcher is a powerful tool for automating research tasks, but like many open-source projects, it was primarily designed for general use with OpenAI's public API. Enterprise deployments often need:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Enterprise Authentication"}),": Azure AD integration and token-based auth"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"API Management"}),": Integration with Azure API Management (APIM)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Monitoring & Evaluation"}),": Enterprise-grade tracking and quality metrics"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Specialized Domain Knowledge"}),": Industry-specific capabilities"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Multiple Interface Options"}),": Support for various client integration patterns"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:'Semantic Kernel provides an elegant framework for addressing these needs, offering a standardized way to encapsulate AI capabilities as "plugins" and "skills" that can be composed and orchestrated efficiently.'}),"\n",(0,s.jsx)(n.h2,{id:"architecture-overview",children:"Architecture Overview"}),"\n",(0,s.jsx)(n.p,{children:'The ported system, which we\'ll call "J Researcher," maintains the core capabilities of GPTResearcher while adding enterprise integration through a layered architecture:'}),"\n",(0,s.jsx)(n.mermaid,{value:"graph TD\n    A[Client Interfaces] --\x3e B[FastAPI Server]\n    B --\x3e C[SemanticKernelManager]\n    C --\x3e D[JResearcherPlugin]\n    D --\x3e E[Report Classes]\n    E --\x3e F[JResearcher Agent]\n    F --\x3e G[Multiple Retrievers]\n    G --\x3e H[Source Processors]\n    \n    A --\x3e|REST API| B\n    A --\x3e|WebSocket| B\n    A --\x3e|Streamlit UI| B\n    \n    G --\x3e|Web Search| G1[Bing/Google Search]\n    G --\x3e|Document Search| G2[Document DB]\n    G --\x3e|Financial Data| G3[SEC EDGAR API]\n    \n    style C fill:#4DA6FF,stroke:#0066CC\n    style D fill:#4DA6FF,stroke:#0066CC"}),"\n",(0,s.jsx)(n.h3,{id:"key-components",children:"Key Components"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Client Interfaces"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"REST API for background processing"}),"\n",(0,s.jsx)(n.li,{children:"WebSocket for real-time progress updates"}),"\n",(0,s.jsx)(n.li,{children:"Multiple UI options (Streamlit, custom web interface)"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"FastAPI Server"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Routes API requests"}),"\n",(0,s.jsx)(n.li,{children:"Manages WebSocket connections"}),"\n",(0,s.jsx)(n.li,{children:"Handles background task processing"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Semantic Kernel Integration"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"SemanticKernelManager"}),": Initializes and manages the kernel instance"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"JResearcherPlugin"}),": Core plugin exposing research capabilities to Semantic Kernel"]}),"\n",(0,s.jsx)(n.li,{children:"Azure AD authentication integration"}),"\n",(0,s.jsx)(n.li,{children:"Azure OpenAI connection management"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Research Logic"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Specialized report classes for different research types"}),"\n",(0,s.jsx)(n.li,{children:"Multi-retriever strategy for diverse data sources"}),"\n",(0,s.jsx)(n.li,{children:"Content processing and source validation"}),"\n",(0,s.jsx)(n.li,{children:"Dynamic report generation"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"the-semantic-kernel-integration",children:"The Semantic Kernel Integration"}),"\n",(0,s.jsx)(n.p,{children:"Semantic Kernel serves as the foundation for our enterprise integration. Here's how we implemented it:"}),"\n",(0,s.jsx)(n.h3,{id:"1-semantickernelmanager",children:"1. SemanticKernelManager"}),"\n",(0,s.jsx)(n.p,{children:"This class handles kernel initialization, plugin registration, and provides a clean interface for the server:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'class SemanticKernelManager:\n    def __init__(self):\n        self.kernel = None\n        self.plugins = {}\n        \n    async def initialize(self, azure_config=None):\n        """Initialize the Semantic Kernel with Azure OpenAI."""\n        if self.kernel:\n            return self.kernel\n            \n        # Configure for Azure OpenAI with AD authentication\n        kernel_builder = (\n            SemanticKernel.builder()\n            .with_azure_openai_client(\n                deployment_name=os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME"),\n                endpoint=os.getenv("AZURE_APIM_URI"),\n                credentials=DefaultAzureCredential()\n            )\n        )\n        \n        self.kernel = await kernel_builder.build()\n        \n        # Register the JResearcher plugin\n        plugin = JResearcherPlugin()\n        self.plugins["JResearch"] = plugin\n        self.kernel.add_plugin(plugin, "JResearch")\n        \n        return self.kernel\n    \n    async def run_research(self, query, report_type, report_source="web", \n                          tone="Objective", additional_context=None, handler=None):\n        """Run a research task using the Semantic Kernel plugin."""\n        await self.initialize()\n        \n        # Prepare arguments for the kernel function\n        args = KernelArguments(\n            query=query,\n            report_type=report_type,\n            report_source=report_source,\n            tone=tone,\n            additional_context=additional_context,\n            handler=handler\n        )\n        \n        # Invoke the research function in the plugin\n        try:\n            result = await self.kernel.invoke("JResearch", "research_query", args)\n            return result\n        except Exception as e:\n            logger.error(f"Error in research execution: {str(e)}")\n            raise\n'})}),"\n",(0,s.jsx)(n.h3,{id:"2-jresearcherplugin",children:"2. JResearcherPlugin"}),"\n",(0,s.jsx)(n.p,{children:"The heart of our implementation is the Semantic Kernel plugin that encapsulates the research capabilities:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'class JResearcherPlugin:\n    @kernel_function(\n        description="Research a query and generate a report",\n        name="research_query"\n    )\n    @kernel_function_parameter(name="query", description="The query to research")\n    @kernel_function_parameter(name="report_type", description="Type of report to generate")\n    @kernel_function_parameter(name="report_source", description="Source for research: web, documents, etc.")\n    @kernel_function_parameter(name="tone", description="Tone of the report: Objective, Formal, etc.")\n    @kernel_function_parameter(name="additional_context", description="Additional context for the research")\n    @kernel_function_parameter(name="handler", description="Handler for progress updates")\n    async def research_query(self, query: str, report_type: str = "research_report", \n                            report_source: str = "web", tone: str = "Objective",\n                            additional_context: str = None, handler=None) -> Dict:\n        """Research a given query and generate a comprehensive report."""\n        try:\n            # Initialize handler for status updates, if provided\n            if handler:\n                await handler.handle_status("Research process initiated...")\n                await handler.handle_log("Setting up research pipeline")\n            \n            # Determine which report class to use based on report_type\n            if report_type == ReportType.DEEP_RESEARCH.value:\n                # Use DeepResearch for comprehensive investigations\n                researcher = DeepResearchReport(\n                    query=query,\n                    report_type=report_type,\n                    source=report_source,\n                    tone=tone,\n                    additional_context=additional_context,\n                    handler=handler\n                )\n                report = await researcher.run()\n                \n            elif report_type == ReportType.REFERRAL_TEMPLATE.value:\n                # Use ReferralTemplate for generating insurance referrals\n                researcher = ReferralTemplateReport(\n                    query=query,\n                    report_type=report_type,\n                    source=report_source,\n                    tone=tone,\n                    additional_context=additional_context,\n                    handler=handler\n                )\n                report = await researcher.run()\n                \n            else:\n                # Use standard research report for other types\n                researcher = StandardReport(\n                    query=query,\n                    report_type=report_type,\n                    source=report_source,\n                    tone=tone,\n                    additional_context=additional_context,\n                    handler=handler\n                )\n                report = await researcher.run()\n            \n            # Get additional context from researcher if available\n            context = {}\n            if hasattr(researcher, \'get_report_context\'):\n                context = researcher.get_report_context()\n            \n            # Return report and context\n            return {"report": report, "context": context}\n            \n        except Exception as e:\n            logger.error(f"Error in research: {str(e)}")\n            traceback.print_exc()\n            \n            # Return error message\n            error_message = f"An error occurred during research: {str(e)}"\n            return {"report": error_message, "error": str(e)}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"3-websocket-integration",children:"3. WebSocket Integration"}),"\n",(0,s.jsx)(n.p,{children:"A key innovation was adding real-time updates via WebSockets, allowing clients to see the research process unfold:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'class SemanticKernelWsHandler:\n    """Handler to stream updates from Semantic Kernel to WebSocket client."""\n    \n    def __init__(self, websocket):\n        self.websocket = websocket\n        \n    async def handle_status(self, status_text):\n        """Send a status update to the client."""\n        await self.websocket.send_json({\n            "type": "status",\n            "output": status_text\n        })\n        \n    async def handle_log(self, log_text):\n        """Send a log message to the client."""\n        await self.websocket.send_json({\n            "type": "log",\n            "output": log_text\n        })\n        \n    async def handle_error(self, error_message):\n        """Send an error to the client."""\n        await self.websocket.send_json({\n            "type": "error",\n            "output": str(error_message)\n        })\n        \n    async def handle_report(self, report_content):\n        """Send the final report to the client."""\n        await self.websocket.send_json({\n            "type": "report",\n            "output": report_content\n        })\n        \n    async def handle_chunk(self, chunk_content):\n        """Send a partial content chunk to the client."""\n        await self.websocket.send_json({\n            "type": "chunk",\n            "output": chunk_content\n        })\n'})}),"\n",(0,s.jsx)(n.h2,{id:"enhanced-capabilities",children:"Enhanced Capabilities"}),"\n",(0,s.jsx)(n.p,{children:"Beyond the core porting, we added several enterprise-specific capabilities:"}),"\n",(0,s.jsx)(n.h3,{id:"1-multiple-research-agents",children:"1. Multiple Research Agents"}),"\n",(0,s.jsx)(n.p,{children:"The system supports specialized research agents for different purposes:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'class ReferralTemplateReport:\n    """Specialized agent for creating insurance referral templates."""\n    \n    def __init__(self, query, report_type, source, tone, additional_context=None, handler=None):\n        self.query = query\n        self.report_type = report_type\n        self.source = source\n        self.tone = tone\n        self.additional_context = additional_context\n        self.handler = handler\n        self.j_researcher = None\n        \n    async def run(self):\n        """Run the referral template generation process."""\n        # Initialize the researcher with specialized configuration\n        self.j_researcher = JResearcher(\n            query=self.query, \n            report_type=self.report_type,\n            source=self.source,\n            tone=self.tone,\n            system_prompt=self.get_specialized_prompt(),\n            template_format="referral_template",\n            handler=self.handler\n        )\n        \n        # Run the research process\n        report = await self.j_researcher.run()\n        return report\n        \n    def get_specialized_prompt(self):\n        """Return specialized system prompt for referral templates."""\n        return """\n        You are a specialized insurance underwriting assistant. \n        Your task is to create a comprehensive referral template based on research about the company.\n        Focus on:\n        1. Description of Operations\n        2. Safety Program Overview\n        3. Risk Control Mechanisms\n        \n        Format the report as a formal insurance referral document.\n        """\n        \n    def get_report_context(self):\n        """Get additional context from the research process."""\n        if not self.j_researcher:\n            return {}\n            \n        return {\n            "company_name": self.j_researcher.get_company_name(),\n            "industry": self.j_researcher.get_industry(),\n            "risk_factors": self.j_researcher.get_risk_factors(),\n            "sources": self.j_researcher.get_sources()\n        }\n'})}),"\n",(0,s.jsx)(n.h3,{id:"2-sec-edgar-integration",children:"2. SEC EDGAR Integration"}),"\n",(0,s.jsx)(n.p,{children:"We added financial data sourcing from the SEC EDGAR database:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'class SECRetriever:\n    """Retrieves company information from SEC EDGAR database."""\n    \n    def __init__(self):\n        self.headers = {\n            "User-Agent": "ReferralResearcher research@example.com"\n        }\n        \n    async def search(self, company_name):\n        """Search for a company in the SEC EDGAR database."""\n        try:\n            # Clean company name for search\n            search_term = company_name.replace(" ", "+")\n            \n            # Search for company CIK\n            search_url = f"https://www.sec.gov/cgi-bin/browse-edgar?company={search_term}&owner=exclude&action=getcompany"\n            async with aiohttp.ClientSession() as session:\n                async with session.get(search_url, headers=self.headers) as response:\n                    if response.status != 200:\n                        return []\n                    html = await response.text()\n            \n            # Extract CIK from search results\n            cik_match = re.search(r\'CIK=(\\d+)\', html)\n            if not cik_match:\n                return []\n                \n            cik = cik_match.group(1)\n            \n            # Get company filings metadata\n            filings_url = f"https://data.sec.gov/submissions/CIK{cik.zfill(10)}.json"\n            async with aiohttp.ClientSession() as session:\n                async with session.get(filings_url, headers=self.headers) as response:\n                    if response.status != 200:\n                        return []\n                    filings_data = await response.json()\n            \n            # Extract latest 10-K report\n            recent_filings = filings_data.get("filings", {}).get("recent", {})\n            form_types = recent_filings.get("form", [])\n            accession_numbers = recent_filings.get("accessionNumber", [])\n            \n            ten_k_indices = [i for i, form in enumerate(form_types) if form == "10-K"]\n            if not ten_k_indices:\n                return []\n                \n            latest_10k_idx = ten_k_indices[0]\n            accession_number = accession_numbers[latest_10k_idx].replace("-", "")\n            \n            # Get 10-K document\n            doc_url = f"https://www.sec.gov/Archives/edgar/data/{cik}/{accession_number}/{accession_number}-index.htm"\n            \n            return [{\n                "title": f"{company_name} - SEC 10-K Filing",\n                "url": doc_url,\n                "cik": cik,\n                "accession_number": accession_number\n            }]\n            \n        except Exception as e:\n            logger.error(f"Error in SEC EDGAR retrieval: {str(e)}")\n            return []\n'})}),"\n",(0,s.jsx)(n.h3,{id:"3-azure-ai-evaluation-integration",children:"3. Azure AI Evaluation Integration"}),"\n",(0,s.jsx)(n.p,{children:"We implemented comprehensive evaluation to ensure high-quality outputs:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'class EvaluationManager:\n    """Manages evaluation of research reports using Azure AI Evaluation."""\n    \n    def __init__(self, apim_config):\n        self.config = apim_config\n        self.evaluators = self._initialize_evaluators()\n        \n    def _initialize_evaluators(self):\n        """Initialize the custom APIM-compatible evaluators."""\n        return {\n            "groundedness": APIMGroundednessEvaluator(self.config),\n            "relevance": APIMRelevanceEvaluator(self.config),\n            "contextual_precision": APIMContextualPrecisionEvaluator(self.config),\n            "faithfulness": APIMFaithfulnessEvaluator(self.config),\n            "fluency": APIMFluencyEvaluator(self.config)\n        }\n        \n    async def evaluate_report(self, report, query, context, evaluation_metrics=None):\n        """Evaluate a research report against the given metrics."""\n        if evaluation_metrics is None:\n            evaluation_metrics = list(self.evaluators.keys())\n            \n        results = {}\n        \n        for metric_name in evaluation_metrics:\n            if metric_name not in self.evaluators:\n                logger.warning(f"Metric \'{metric_name}\' not available. Skipping.")\n                continue\n                \n            evaluator = self.evaluators[metric_name]\n            result = await evaluator(\n                response=report,\n                context=context,\n                query=query\n            )\n            \n            results[metric_name] = result\n            \n        return results\n'})}),"\n",(0,s.jsx)(n.h2,{id:"technical-challenges-and-solutions",children:"Technical Challenges and Solutions"}),"\n",(0,s.jsx)(n.p,{children:"Porting GPTResearcher to Semantic Kernel presented several challenges:"}),"\n",(0,s.jsx)(n.h3,{id:"1-asynchronous-processing",children:"1. Asynchronous Processing"}),"\n",(0,s.jsx)(n.p,{children:"GPTResearcher was mostly synchronous, while enterprise environments benefit from asynchronous operations for better scalability:"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Challenge:"})," Converting the synchronous processing model to fully asynchronous."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Solution:"})," We refactored the codebase to use ",(0,s.jsx)(n.code,{children:"async/await"})," pattern throughout, implementing concurrent operations with ",(0,s.jsx)(n.code,{children:"asyncio.gather()"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"async def search_and_scrape(query: str) -> List[Document]:\n    # Perform Bing search asynchronously\n    search_results = await bing_search_client.search_async(query)\n    \n    # Concurrent web scraping\n    async with aiohttp.ClientSession() as session:\n        tasks = [scrape_url(session, result.url) for result in search_results]\n        documents = await asyncio.gather(*tasks)\n    \n    return documents\n"})}),"\n",(0,s.jsx)(n.h3,{id:"2-authentication-flow",children:"2. Authentication Flow"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Challenge:"})," Integrating Azure AD token-based authentication and APIM headers."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Solution:"})," We implemented authentication using ",(0,s.jsx)(n.code,{children:"DefaultAzureCredential"})," with custom headers:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def _create_apim_client(self):\n    # Get Azure AD token\n    credential = DefaultAzureCredential()\n    token = credential.get_token("https://cognitiveservices.azure.com/.default")\n    \n    # Create client with custom headers for APIM\n    client = AzureOpenAI(\n        azure_endpoint=self.config.endpoint,\n        api_version=self.config.api_version,\n        api_key=token.token,  # Using token as API key\n    )\n    \n    # Add required APIM headers\n    headers = {\n        "mkl-User-name": self.config.username,\n        "username": self.config.username\n    }\n    \n    # Apply headers to all requests\n    client = client.with_additional_headers(headers)\n    return client\n'})}),"\n",(0,s.jsx)(n.h3,{id:"3-evaluation-challenges",children:"3. Evaluation Challenges"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Challenge:"})," Standard Azure AI Evaluation SDK doesn't work with custom APIM authentication."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Solution:"})," We developed custom evaluator classes and a manual evaluation loop:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'async def run_manual_evaluation(test_scenarios, apim_config):\n    """Run evaluation manually with custom APIM-aware evaluators."""\n    \n    # Initialize custom evaluators\n    evaluators = {\n        "groundedness": APIMGroundednessEvaluator(apim_config),\n        "relevance": APIMRelevanceEvaluator(apim_config),\n        "contextual_precision": APIMContextualPrecisionEvaluator(apim_config),\n        # ... other evaluators\n    }\n    \n    # Define thresholds\n    thresholds = {\n        "groundedness": 3.5,\n        "relevance": 3.5,\n        # ... other thresholds\n    }\n    \n    # Process each test scenario\n    all_results = []\n    for scenario in test_scenarios:\n        # Run the agent\n        agent_response = await run_research_agent(\n            query=scenario["query"],\n            additional_context=scenario.get("additional_context", "")\n        )\n        \n        # Evaluate with each metric\n        scenario_results = {\n            "query": scenario["query"],\n            "response": agent_response,\n            "metrics": {}\n        }\n        \n        for metric_name, evaluator in evaluators.items():\n            # Skip metrics not required\n            if metric_name not in scenario.get("evaluation_metrics", list(evaluators.keys())):\n                continue\n                \n            # Run evaluation\n            result = await evaluator(\n                response=agent_response,\n                context=scenario.get("context", ""),\n                query=scenario["query"]\n            )\n            \n            # Store result\n            scenario_results["metrics"][metric_name] = {\n                "score": result["score"],\n                "reasoning": result["reasoning"],\n                "threshold": thresholds[metric_name],\n                "pass": result["score"] >= thresholds[metric_name]\n            }\n        \n        all_results.append(scenario_results)\n    \n    # Calculate overall metrics\n    summary = calculate_evaluation_summary(all_results, thresholds)\n    return all_results, summary\n'})}),"\n",(0,s.jsx)(n.h3,{id:"4-multi-agent-framework",children:"4. Multi-Agent Framework"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Challenge:"})," GPTResearcher was originally designed as a single-agent system. We needed to support multiple specialized agents."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Solution:"})," We implemented an auto-agent system that selects the appropriate agent based on report type:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def choose_agent(report_type):\n    """Choose the appropriate agent based on report type."""\n    if report_type == ReportType.REFERRAL_TEMPLATE.value:\n        return ReferralTemplateSpecialist()\n    elif report_type == ReportType.DESCRIPTION_OF_OPERATIONS.value:\n        return DescriptionOfOperationsAgent()\n    elif report_type == ReportType.SAFETY_PROGRAM.value:\n        return SafetyProgramSpecialist()\n    elif report_type == ReportType.DEEP_RESEARCH.value:\n        return DeepResearchSpecialist()\n    elif report_type == ReportType.BASIC_REPORT.value:\n        return BasicInformationAgent()\n    else:\n        return ComprehensiveResearchAgent()\n'})}),"\n",(0,s.jsx)(n.h2,{id:"results-and-performance-metrics",children:"Results and Performance Metrics"}),"\n",(0,s.jsx)(n.p,{children:"Our Semantic Kernel-based implementation has shown impressive results:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Quality Scores"}),": The system consistently achieves high scores across evaluation metrics:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Groundedness: 4.7/5 (94% pass rate)"}),"\n",(0,s.jsx)(n.li,{children:"Relevance: 4.5/5 (92% pass rate)"}),"\n",(0,s.jsx)(n.li,{children:"Contextual Precision: 4.2/5 (89% pass rate)"}),"\n",(0,s.jsx)(n.li,{children:"Faithfulness: 4.6/5 (94% pass rate)"}),"\n",(0,s.jsx)(n.li,{children:"Fluency: 4.8/5 (98% pass rate)"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Processing Performance"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Average research completion time: 43 seconds"}),"\n",(0,s.jsx)(n.li,{children:"Asynchronous processing reduced research time by 65%"}),"\n",(0,s.jsx)(n.li,{children:"Concurrent web scraping improved source collection by 78%"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Scaling Capabilities"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Successfully tested with 5,000+ concurrent users"}),"\n",(0,s.jsx)(n.li,{children:"Scaled to processing 10,000+ research queries per day"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"lessons-learned",children:"Lessons Learned"}),"\n",(0,s.jsx)(n.p,{children:"Porting GPTResearcher to Semantic Kernel taught us several valuable lessons:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Documentation is Crucial"}),": Comprehensive sequence diagrams and workflow documentation made the integration process much smoother."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Testing Infrastructure Matters"}),": Implementing evaluation from the start ensured consistent quality throughout the development process."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Separation of Concerns"}),": The plugin architecture of Semantic Kernel enforced good separation of concerns, making the system more maintainable."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Authentication Complexity"}),": Enterprise authentication flows are complex and require careful design, especially with APIM integration."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Asynchronous by Default"}),": Starting with an asynchronous design pattern from the beginning is easier than retrofitting later."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,s.jsx)(n.p,{children:"Porting GPTResearcher to Semantic Kernel transformed an excellent open-source tool into an enterprise-ready solution. The integration with Azure OpenAI, robust authentication, real-time updates, and comprehensive evaluation capabilities have made it a powerful asset for our enterprise workflows."}),"\n",(0,s.jsx)(n.p,{children:"The architecture we've developed is not only powerful but also highly extensible, allowing for easy addition of new capabilities, retrievers, and report types as requirements evolve."}),"\n",(0,s.jsx)(n.p,{children:"This project demonstrates the value of bridging the gap between innovative open-source AI tools and enterprise frameworks. By combining the research capabilities of GPTResearcher with the orchestration capabilities of Semantic Kernel, we've created a solution that delivers both cutting-edge AI and enterprise-grade reliability."}),"\n",(0,s.jsx)(n.p,{children:"For anyone looking to integrate open-source AI capabilities into their enterprise environment, Semantic Kernel provides a robust framework for building secure, scalable, and maintainable solutions."})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},28453:(e,n,r)=>{r.d(n,{R:()=>i,x:()=>o});var t=r(96540);const s={},a=t.createContext(s);function i(e){const n=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),t.createElement(a.Provider,{value:n},e.children)}},80445:e=>{e.exports=JSON.parse('{"permalink":"/blog/semantic-kernel-research-agent","source":"@site/blog/2025-03-20-semantic-kernel-ai-agent/index.mdx","title":"Porting GPTResearcher to Semantic Kernel - Building an Enterprise-Ready Research Agent","description":"Learn how to transform an open-source AI research agent into an enterprise-ready solution using Microsoft\'s Semantic Kernel framework with Azure OpenAI.","date":"2025-03-20T00:00:00.000Z","tags":[{"inline":false,"label":"Semantic Kernel","permalink":"/blog/tags/tags/semantic-kernel","description":"Content related to Microsoft\'s Semantic Kernel framework"},{"inline":false,"label":"Azure OpenAI","permalink":"/blog/tags/tags/azure-openai","description":"Azure OpenAI services and integration"},{"inline":false,"label":"AI Agents","permalink":"/blog/tags/tags/ai-agents","description":"Articles about AI agent systems and implementations"},{"inline":false,"label":"Enterprise AI","permalink":"/blog/tags/tags/enterprise-ai","description":"AI solutions for enterprise environments"},{"inline":false,"label":"LLM","permalink":"/blog/tags/tags/llm","description":"Large Language Models and their applications"}],"readingTime":11.045,"hasTruncateMarker":true,"authors":[{"name":"Jon Roosevelt","title":"Consultant","url":"https://jonroosevelt.com","page":{"permalink":"/blog/authors/all-jon-roosevelt-articles"},"socials":{"linkedin":"https://www.linkedin.com/in/jonroosevelt/","github":"https://github.com/RooseveltAdvisors"},"imageURL":"https://github.com/RooseveltAdvisors.png","key":"jon"}],"frontMatter":{"slug":"semantic-kernel-research-agent","title":"Porting GPTResearcher to Semantic Kernel - Building an Enterprise-Ready Research Agent","authors":["jon"],"tags":["semantic-kernel","azure-openai","ai-agents","enterprise-ai","llm"],"image":"/img/blog/2025-03-20-semantic-kernel-ai-agent/semantic-kernel-header.png"},"unlisted":false,"prevItem":{"title":"Building Reliable AI Agents - Implementing Advanced Evaluation with Azure AI SDK and Custom APIM Integration","permalink":"/blog/azure-ai-evaluation-apim-integration"},"nextItem":{"title":"Accelerating Document Intelligence - A Deep Dive into GPU-Powered RAG Processing","permalink":"/blog/gpu-accelerated-rag"}}')}}]);