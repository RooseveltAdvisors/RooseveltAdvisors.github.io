"use strict";(self.webpackChunkroosevelt_advisors_website=self.webpackChunkroosevelt_advisors_website||[]).push([[8421],{4459:e=>{e.exports=JSON.parse('{"permalink":"/blog/2024/11/26/defining-pii-masking-policies-with-aws-bedrock-guardrails","source":"@site/blog/2024-11-26-defining-pii-masking-policies-with-aws-bedrock-guardrails/index.mdx","title":"Defining PII Masking Policies with AWS Bedrock Guardrails","description":"Introduction","date":"2024-11-26T00:00:00.000Z","tags":[{"inline":false,"label":"AWS","permalink":"/blog/tags/tags/aws","description":"Content related to Amazon Web Services and its offerings"},{"inline":false,"label":"Bedrock","permalink":"/blog/tags/tags/bedrock","description":"Content related to AWS Bedrock services"},{"inline":false,"label":"Guardrails","permalink":"/blog/tags/tags/guardrails","description":"Content related to AI safety guardrails and policies"},{"inline":false,"label":"PII","permalink":"/blog/tags/tags/pii","description":"Content related to Personally Identifiable Information handling"},{"inline":false,"label":"Data Privacy","permalink":"/blog/tags/tags/data-privacy","description":"Content related to data privacy principles and practices"},{"inline":false,"label":"AI Safety","permalink":"/blog/tags/tags/ai-safety","description":"Content related to ensuring the safety and reliability of AI systems"},{"inline":false,"label":"LLM","permalink":"/blog/tags/tags/llm","description":"Large Language Models and their applications"},{"inline":false,"label":"GenAI","permalink":"/blog/tags/tags/genai","description":"Content related to Generative AI models and applications"}],"readingTime":4.025,"hasTruncateMarker":true,"authors":[{"name":"Jon Roosevelt","title":"Consultant","url":"https://jonroosevelt.com","page":{"permalink":"/blog/authors/all-jon-roosevelt-articles"},"socials":{"linkedin":"https://www.linkedin.com/in/jonroosevelt/","github":"https://github.com/RooseveltAdvisors"},"imageURL":"https://github.com/RooseveltAdvisors.png","key":"jon"}],"frontMatter":{"title":"Defining PII Masking Policies with AWS Bedrock Guardrails","authors":["jon"],"date":"2024-11-26T00:00:00.000Z","tags":["aws","bedrock","guardrails","pii","data-privacy","ai-safety","llm","genai"],"image":"/img/blog/defining-pii-masking-policies-with-aws-bedrock-guardrails/image1.png"},"unlisted":false,"prevItem":{"title":"Building an Enterprise-Grade RAG System - A Deep Dive into Advanced Document Intelligence","permalink":"/blog/enterprise-rag-system"},"nextItem":{"title":"Fine-Tuning Microsoft Phi-2 for Sentiment Analysis - A Step-by-Step Guide","permalink":"/blog/fine-tuning-microsoft-phi-2-for-sentiment-analysis"}}')},17214:(e,i,t)=>{t.r(i),t.d(i,{assets:()=>l,contentTitle:()=>r,default:()=>g,frontMatter:()=>o,metadata:()=>n,toc:()=>d});var n=t(4459),a=t(74848),s=t(28453);const o={title:"Defining PII Masking Policies with AWS Bedrock Guardrails",authors:["jon"],date:new Date("2024-11-26T00:00:00.000Z"),tags:["aws","bedrock","guardrails","pii","data-privacy","ai-safety","llm","genai"],image:"/img/blog/defining-pii-masking-policies-with-aws-bedrock-guardrails/image1.png"},r=void 0,l={authorsImageUrls:[void 0]},d=[{value:"<strong>Introduction</strong>",id:"introduction",level:2},{value:"<strong>What is Amazon Bedrock Guardrails?</strong>",id:"what-is-amazon-bedrock-guardrails",level:2}];function c(e){const i={h2:"h2",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(i.p,{children:(0,a.jsx)(i.img,{src:t(25698).A+"",width:"2752",height:"1536"})}),"\n",(0,a.jsx)(i.h2,{id:"introduction",children:(0,a.jsx)(i.strong,{children:"Introduction"})}),"\n",(0,a.jsx)(i.h2,{id:"what-is-amazon-bedrock-guardrails",children:(0,a.jsx)(i.strong,{children:"What is Amazon Bedrock Guardrails?"})}),"\n",(0,a.jsxs)(i.ul,{children:["\n",(0,a.jsx)(i.li,{children:"Amazon Bedrock Guardrails are a robust feature within the Amazon Bedrock service designed to enhance the safety, compliance, and overall quality of interactions with AI models. Guardrails provide a comprehensive set of tools that allow organizations to define and enforce content policies, ensuring that the AI models deployed adhere to specific guidelines and avoid generating inappropriate, sensitive, or off-topic content."}),"\n"]})]})}function g(e={}){const{wrapper:i}={...(0,s.R)(),...e.components};return i?(0,a.jsx)(i,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},25698:(e,i,t)=>{t.d(i,{A:()=>n});const n=t.p+"assets/images/image1-5595abfb60b0b363182fdac6359bf554.png"},28453:(e,i,t)=>{t.d(i,{R:()=>o,x:()=>r});var n=t(96540);const a={},s=n.createContext(a);function o(e){const i=n.useContext(s);return n.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function r(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),n.createElement(s.Provider,{value:i},e.children)}}}]);