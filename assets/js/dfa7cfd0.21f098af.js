"use strict";(self.webpackChunkroosevelt_advisors_website=self.webpackChunkroosevelt_advisors_website||[]).push([[9470],{5858:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/modular-agents-header-236580a955f2c533f3ee3b655e339790.png"},28453:(e,n,t)=>{t.d(n,{R:()=>l,x:()=>r});var s=t(96540);const i={},a=s.createContext(i);function l(e){const n=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),s.createElement(a.Provider,{value:n},e.children)}},48174:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>o,contentTitle:()=>r,default:()=>u,frontMatter:()=>l,metadata:()=>s,toc:()=>c});var s=t(57384),i=t(74848),a=t(28453);const l={slug:"architecting-modular-ai-agents",title:"Architecting Extensible AI Agents - A Modular Core with Pluggable Skills and SSE Communication",authors:["jon"],tags:["ai-agents","microservices","sse","architecture","modular-design"],image:"/img/blog/2025-04-05-modular-ai-agents/hero-banner.jpg"},r="Architecting Extensible AI Agents: A Modular Core with Pluggable Skills and SSE Communication",o={authorsImageUrls:[void 0]},c=[{value:"The Problem with Monolithic Agents",id:"the-problem-with-monolithic-agents",level:2},{value:"A Modular, Skill-Based Architecture",id:"a-modular-skill-based-architecture",level:2},{value:"The Agent Core",id:"the-agent-core",level:3},{value:"Skills as Independent Services",id:"skills-as-independent-services",level:3},{value:"SSE for Real-Time Communication",id:"sse-for-real-time-communication",level:3},{value:"The Translation Skill: A Case Study",id:"the-translation-skill-a-case-study",level:2},{value:"Integration with MCP Protocol",id:"integration-with-mcp-protocol",level:2},{value:"Client Implementation",id:"client-implementation",level:2},{value:"Deployment and Scaling",id:"deployment-and-scaling",level:2},{value:"Benefits of this Architecture",id:"benefits-of-this-architecture",level:2},{value:"Challenges and Considerations",id:"challenges-and-considerations",level:2},{value:"1. Increased Operational Complexity",id:"1-increased-operational-complexity",level:3},{value:"2. Consistency Across Skills",id:"2-consistency-across-skills",level:3},{value:"3. Error Handling",id:"3-error-handling",level:3},{value:"4. State Management",id:"4-state-management",level:3},{value:"Performance and Monitoring",id:"performance-and-monitoring",level:2},{value:"Conclusion",id:"conclusion",level:2}];function d(e){const n={code:"code",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.p,{children:"Learn how to architect AI agent systems with a modular, skill-based approach and implement real-time communication using Server-Sent Events (SSE)."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Modular AI Agent Architecture",src:t(5858).A+"",width:"2752",height:"1536"})}),"\n","\n",(0,i.jsx)(n.p,{children:'AI agents have become increasingly sophisticated, but their architecture often struggles to scale as complexity increases. Monolithic agent designs, where all capabilities are tightly coupled into a single codebase, become unwieldy as feature requirements expand. In this post, I\'ll share a modular approach to AI agent architecture that addresses these challenges by separating core orchestration logic from specialized "skills" and implementing efficient real-time communication using Server-Sent Events (SSE).'}),"\n",(0,i.jsx)(n.h2,{id:"the-problem-with-monolithic-agents",children:"The Problem with Monolithic Agents"}),"\n",(0,i.jsx)(n.p,{children:"Before diving into the solution, let's understand why traditional monolithic agent designs become problematic:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Tight Coupling"}),": When all capabilities are intertwined, changes to one feature risk breaking others."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Poor Scalability"}),": Both technical (codebase complexity) and team (developer coordination) scalability suffer."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Limited Extensibility"}),": Adding new capabilities often requires modifying core agent code."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Deployment Challenges"}),": The entire agent must be redeployed for any change, increasing downtime risk."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Technology Lock-in"}),": Using different technologies for different capabilities becomes difficult."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"As we developed more sophisticated AI agents with multiple capabilities, these limitations became increasingly apparent. We needed a better approach."}),"\n",(0,i.jsx)(n.h2,{id:"a-modular-skill-based-architecture",children:"A Modular, Skill-Based Architecture"}),"\n",(0,i.jsx)(n.p,{children:"The solution is a modular architecture that separates concerns and enables independent development and deployment of agent capabilities. At its core, this architecture has three main components:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Agent Core"}),": Handles orchestration, state management, and communication."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Skills"}),": Independent modules that implement specific capabilities."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Communication Layer"}),": Enables real-time interaction between the core and skills."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Let's look at the implementation of each component:"}),"\n",(0,i.jsx)(n.h3,{id:"the-agent-core",children:"The Agent Core"}),"\n",(0,i.jsx)(n.p,{children:"The agent core functions as a central hub, responsible for:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Managing the overall agent state"}),"\n",(0,i.jsx)(n.li,{children:"Orchestrating skill execution"}),"\n",(0,i.jsx)(n.li,{children:"Handling user interactions"}),"\n",(0,i.jsx)(n.li,{children:"Providing a unified API for clients"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Here's a simplified implementation of the agent core:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class AgentCore:\n    def __init__(self):\n        self.skills = {}  # Registered skills\n        self.state = {}   # Agent state\n        self.session_store = SessionStore()  # For persisting sessions\n        \n    def register_skill(self, skill_name, skill_endpoint):\n        """Register a skill with the agent core."""\n        self.skills[skill_name] = skill_endpoint\n        logger.info(f"Registered skill: {skill_name} at {skill_endpoint}")\n        \n    async def execute_skill(self, skill_name, input_data):\n        """Execute a specific skill and return results."""\n        if skill_name not in self.skills:\n            raise SkillNotFoundError(f"Skill \'{skill_name}\' not registered")\n            \n        skill_endpoint = self.skills[skill_name]\n        \n        # Create SSE client to receive real-time updates\n        async with SSEClient(f"{skill_endpoint}/execute") as client:\n            # Send initial request\n            await client.send_request(input_data)\n            \n            # Process SSE events\n            async for event in client:\n                event_data = json.loads(event.data)\n                event_type = event.event or "update"\n                \n                # Handle different event types\n                if event_type == "status":\n                    self.state["status"] = event_data["status"]\n                    yield {"type": "status", "data": event_data}\n                    \n                elif event_type == "thinking":\n                    yield {"type": "thinking", "data": event_data["content"]}\n                    \n                elif event_type == "result":\n                    self.state["last_result"] = event_data\n                    yield {"type": "result", "data": event_data}\n                    \n                elif event_type == "error":\n                    yield {"type": "error", "data": event_data["message"]}\n    \n    async def process_request(self, user_request):\n        """Process a user request, determining which skill to use."""\n        # Determine appropriate skill based on request\n        skill_name = self.determine_skill(user_request)\n        \n        # Execute the skill and stream results\n        async for update in self.execute_skill(skill_name, user_request):\n            yield update\n            \n    def determine_skill(self, request):\n        """Determine which skill should handle a request."""\n        # This could use LLM-based routing, rule-based matching, etc.\n        # Simplified implementation for demonstration\n        if "translate" in request.get("action", "").lower():\n            return "translation"\n        elif "ground" in request.get("action", "").lower():\n            return "grounding"\n        else:\n            return "default"\n'})}),"\n",(0,i.jsx)(n.h3,{id:"skills-as-independent-services",children:"Skills as Independent Services"}),"\n",(0,i.jsx)(n.p,{children:"Skills are implemented as standalone services with their own API endpoints. Each skill:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Has a well-defined interface for communication with the core"}),"\n",(0,i.jsx)(n.li,{children:"Manages its own dependencies and resources"}),"\n",(0,i.jsx)(n.li,{children:"Can be developed, tested, and deployed independently"}),"\n",(0,i.jsx)(n.li,{children:"Exposes an SSE endpoint for real-time updates"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Here's an example of a grounding skill that helps validate inputs against reliable sources:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class GroundingSkill:\n    def __init__(self):\n        self.llm_client = LLMClient()  # LLM service client\n        self.search_client = SearchClient()  # Web search client\n        \n    async def ground(self, statement, search_results=None):\n        """Ground a statement using search results or by performing a search."""\n        # Get search results if not provided\n        if not search_results:\n            search_results = await self.search_client.search(statement)\n            \n        # Use LLM to evaluate statement against search results\n        evaluation = await self.llm_client.evaluate_grounding(\n            statement=statement,\n            sources=search_results\n        )\n        \n        return {\n            "statement": statement,\n            "is_grounded": evaluation["is_grounded"],\n            "confidence": evaluation["confidence"],\n            "sources": evaluation["relevant_sources"],\n            "reasoning": evaluation["reasoning"]\n        }\n    \n    async def process_grounding_request(self, request, sse_response):\n        """Process a grounding request with SSE updates."""\n        statement = request.get("statement", "")\n        \n        # Send status update\n        await sse_response.send(\n            data=json.dumps({"status": "Searching for relevant information"}),\n            event="status"\n        )\n        \n        # Perform search\n        search_results = await self.search_client.search(statement)\n        \n        # Send thinking update\n        await sse_response.send(\n            data=json.dumps({"content": "Analyzing search results for relevant information"}),\n            event="thinking"\n        )\n        \n        # Ground the statement\n        result = await self.ground(statement, search_results)\n        \n        # Send final result\n        await sse_response.send(\n            data=json.dumps(result),\n            event="result"\n        )\n'})}),"\n",(0,i.jsx)(n.p,{children:"This skill can be deployed as a separate microservice with FastAPI:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from fastapi import FastAPI, Request\nfrom sse_starlette.sse import EventSourceResponse\n\napp = FastAPI()\ngrounding_skill = GroundingSkill()\n\n@app.post("/execute")\nasync def execute_skill(request: Request):\n    """Execute the grounding skill with SSE updates."""\n    request_data = await request.json()\n    \n    async def event_generator():\n        try:\n            await grounding_skill.process_grounding_request(request_data, SSEResponse())\n        except Exception as e:\n            # Send error event\n            await SSEResponse().send(\n                data=json.dumps({"message": str(e)}),\n                event="error"\n            )\n    \n    return EventSourceResponse(event_generator())\n\nclass SSEResponse:\n    """Helper class to send SSE events."""\n    async def send(self, data, event=None):\n        if event:\n            return {"event": event, "data": data}\n        return {"data": data}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"sse-for-real-time-communication",children:"SSE for Real-Time Communication"}),"\n",(0,i.jsx)(n.p,{children:"A critical aspect of this architecture is the real-time communication between the agent core and skills. We chose Server-Sent Events (SSE) over alternatives like WebSockets for several reasons:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Simplicity"}),": SSE is simpler to implement than WebSockets, especially for one-way communication."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"HTTP-Based"}),": SSE works over standard HTTP, making it easier to deploy and debug."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Automatic Reconnection"}),": Browsers handle reconnection for SSE automatically."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Message Types"}),": SSE supports named events, which helps organize different update types."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Our implementation includes custom SSE classes for both client and server sides:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class SSEClient:\n    """Client for connecting to SSE endpoints and sending initial requests."""\n    \n    def __init__(self, url):\n        self.url = url\n        self.session = None\n        self.response = None\n        \n    async def __aenter__(self):\n        self.session = aiohttp.ClientSession()\n        return self\n        \n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        if self.session:\n            await self.session.close()\n            \n    async def send_request(self, data):\n        """Send initial request to the SSE endpoint."""\n        headers = {\n            "Content-Type": "application/json",\n            "Accept": "text/event-stream"\n        }\n        self.response = await self.session.post(\n            self.url,\n            json=data,\n            headers=headers\n        )\n        \n    async def __aiter__(self):\n        """Iterate through SSE events."""\n        if not self.response:\n            return\n            \n        # Process the SSE stream\n        buffer = ""\n        async for line in self.response.content:\n            line = line.decode(\'utf-8\')\n            buffer += line\n            \n            if buffer.endswith(\'\\n\\n\'):\n                event = self._parse_event(buffer.strip())\n                if event:\n                    yield event\n                buffer = ""\n                \n    def _parse_event(self, data):\n        """Parse an SSE event from string data."""\n        if not data:\n            return None\n            \n        lines = data.split(\'\\n\')\n        event_data = {}\n        \n        for line in lines:\n            if line.startswith(\'data:\'):\n                event_data[\'data\'] = line[5:].strip()\n            elif line.startswith(\'event:\'):\n                event_data[\'event\'] = line[6:].strip()\n            elif line.startswith(\'id:\'):\n                event_data[\'id\'] = line[3:].strip()\n                \n        return event_data if \'data\' in event_data else None\n'})}),"\n",(0,i.jsx)(n.h2,{id:"the-translation-skill-a-case-study",children:"The Translation Skill: A Case Study"}),"\n",(0,i.jsx)(n.p,{children:"Let's look at a complete example of another skill implementation - the translation skill:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class TranslationSkill:\n    """Skill for translating text between languages."""\n    \n    def __init__(self):\n        self.llm_client = LLMClient()\n        self.supported_languages = self._load_supported_languages()\n        \n    def _load_supported_languages(self):\n        """Load supported language codes and names."""\n        # In practice, this would load from a configuration file\n        return {\n            "en": "English",\n            "es": "Spanish",\n            "fr": "French",\n            "de": "German",\n            "zh": "Chinese",\n            "ja": "Japanese",\n            # ... more languages\n        }\n        \n    async def translate(self, text, source_lang, target_lang):\n        """Translate text from source language to target language."""\n        # Validate languages\n        if source_lang not in self.supported_languages:\n            raise ValueError(f"Unsupported source language: {source_lang}")\n        if target_lang not in self.supported_languages:\n            raise ValueError(f"Unsupported target language: {target_lang}")\n            \n        # Use LLM for translation\n        prompt = f"""\n        Translate the following text from {self.supported_languages[source_lang]} to {self.supported_languages[target_lang]}:\n        \n        {text}\n        \n        Provide only the translated text without any additional explanation.\n        """\n        \n        response = await self.llm_client.generate(prompt)\n        \n        return {\n            "original_text": text,\n            "translated_text": response.strip(),\n            "source_language": source_lang,\n            "target_language": target_lang\n        }\n        \n    async def process_translation_request(self, request, sse_response):\n        """Process a translation request with SSE updates."""\n        text = request.get("text", "")\n        source_lang = request.get("source_lang", "auto")\n        target_lang = request.get("target_lang", "en")\n        \n        # If source language is auto, detect it\n        if source_lang == "auto":\n            await sse_response.send(\n                data=json.dumps({"status": "Detecting language"}),\n                event="status"\n            )\n            source_lang = await self._detect_language(text)\n            \n        # Send status update\n        await sse_response.send(\n            data=json.dumps({\n                "status": f"Translating from {self.supported_languages.get(source_lang, source_lang)} to {self.supported_languages.get(target_lang, target_lang)}"\n            }),\n            event="status"\n        )\n        \n        # Send thinking update\n        await sse_response.send(\n            data=json.dumps({\n                "content": "Processing translation request..."\n            }),\n            event="thinking"\n        )\n        \n        # Perform translation\n        result = await self.translate(text, source_lang, target_lang)\n        \n        # Send final result\n        await sse_response.send(\n            data=json.dumps(result),\n            event="result"\n        )\n        \n    async def _detect_language(self, text):\n        """Detect the language of the input text."""\n        prompt = f"""\n        Identify the language of the following text. Respond with only the ISO 639-1 \n        language code (e.g., \'en\' for English, \'es\' for Spanish):\n        \n        {text}\n        """\n        \n        response = await self.llm_client.generate(prompt)\n        detected_lang = response.strip().lower()\n        \n        # Default to English if detection fails\n        if detected_lang not in self.supported_languages:\n            return "en"\n            \n        return detected_lang\n'})}),"\n",(0,i.jsx)(n.h2,{id:"integration-with-mcp-protocol",children:"Integration with MCP Protocol"}),"\n",(0,i.jsx)(n.p,{children:"For our implementation, we integrated the skills with the MCP (Model Control Protocol) for consistent message formatting and handling. MCP provides a standardized way for models and agents to communicate with clients:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class MCPHandler:\n    """Handles MCP protocol formatting for SSE events."""\n    \n    @staticmethod\n    def format_thinking(thinking_text):\n        """Format thinking update in MCP format."""\n        return {\n            "type": "thinking",\n            "content": thinking_text,\n            "timestamp": datetime.now().isoformat()\n        }\n    \n    @staticmethod\n    def format_status(status_text):\n        """Format status update in MCP format."""\n        return {\n            "type": "status",\n            "status": status_text,\n            "timestamp": datetime.now().isoformat()\n        }\n    \n    @staticmethod\n    def format_result(result_data):\n        """Format final result in MCP format."""\n        return {\n            "type": "result",\n            "content": result_data,\n            "timestamp": datetime.now().isoformat()\n        }\n    \n    @staticmethod\n    def format_error(error_message):\n        """Format error in MCP format."""\n        return {\n            "type": "error",\n            "message": error_message,\n            "timestamp": datetime.now().isoformat()\n        }\n'})}),"\n",(0,i.jsx)(n.h2,{id:"client-implementation",children:"Client Implementation"}),"\n",(0,i.jsx)(n.p,{children:"Clients can connect to the agent core and receive real-time updates through SSE:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-javascript",children:"// Client-side JavaScript for connecting to the agent\nconst connectToAgent = async (request) => {\n    const response = await fetch('/api/agent/process', {\n        method: 'POST',\n        headers: {\n            'Content-Type': 'application/json',\n            'Accept': 'text/event-stream'\n        },\n        body: JSON.stringify(request)\n    });\n    \n    const reader = response.body.getReader();\n    const decoder = new TextDecoder();\n    \n    // Process the SSE stream\n    while (true) {\n        const { done, value } = await reader.read();\n        if (done) break;\n        \n        const chunk = decoder.decode(value);\n        const events = chunk.split('\\n\\n').filter(Boolean);\n        \n        for (const eventText of events) {\n            const eventData = parseSSEEvent(eventText);\n            \n            switch (eventData.type) {\n                case 'status':\n                    updateStatus(eventData.data.status);\n                    break;\n                case 'thinking':\n                    updateThinking(eventData.data.content);\n                    break;\n                case 'result':\n                    displayResult(eventData.data);\n                    break;\n                case 'error':\n                    showError(eventData.data.message);\n                    break;\n            }\n        }\n    }\n};\n\nconst parseSSEEvent = (eventText) => {\n    const lines = eventText.split('\\n');\n    const eventData = {};\n    \n    for (const line of lines) {\n        if (line.startsWith('event: ')) {\n            eventData.type = line.substring(7);\n        } else if (line.startsWith('data: ')) {\n            eventData.data = JSON.parse(line.substring(6));\n        }\n    }\n    \n    return eventData;\n};\n"})}),"\n",(0,i.jsx)(n.h2,{id:"deployment-and-scaling",children:"Deployment and Scaling"}),"\n",(0,i.jsx)(n.p,{children:"This modular architecture simplifies deployment and scaling. Each component can be deployed independently:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'# Example docker-compose.yml for deploying the system\nversion: \'3\'\n\nservices:\n  agent-core:\n    build: ./agent-core\n    ports:\n      - "8080:8080"\n    environment:\n      - GROUNDING_SKILL_URL=http://grounding-skill:8081\n      - TRANSLATION_SKILL_URL=http://translation-skill:8082\n    depends_on:\n      - grounding-skill\n      - translation-skill\n    networks:\n      - agent-network\n      \n  grounding-skill:\n    build: ./grounding-skill\n    ports:\n      - "8081:8081"\n    environment:\n      - OPENAI_API_KEY=${OPENAI_API_KEY}\n    networks:\n      - agent-network\n      \n  translation-skill:\n    build: ./translation-skill\n    ports:\n      - "8082:8082"\n    environment:\n      - OPENAI_API_KEY=${OPENAI_API_KEY}\n    networks:\n      - agent-network\n\nnetworks:\n  agent-network:\n    driver: bridge\n'})}),"\n",(0,i.jsx)(n.p,{children:"For Kubernetes deployment, we use Helm charts to manage the deployment of each component:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"# Simplified Helm values.yaml example\nreplicaCount:\n  agentCore: 2\n  groundingSkill: 3\n  translationSkill: 3\n\nimages:\n  repository:\n    agentCore: agent-core\n    groundingSkill: grounding-skill\n    translationSkill: translation-skill\n  tag: latest\n  pullPolicy: Always\n\nservice:\n  type: ClusterIP\n  port: 80\n"})}),"\n",(0,i.jsx)(n.h2,{id:"benefits-of-this-architecture",children:"Benefits of this Architecture"}),"\n",(0,i.jsx)(n.p,{children:"This modular architecture with SSE communication provides numerous benefits:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Independent Development"}),": Teams can work on different skills without affecting each other."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Flexible Scaling"}),": Each skill can be scaled independently based on usage patterns."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Technology Flexibility"}),": Different skills can use different technologies or languages as needed."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Incremental Deployment"}),": New skills can be added without redeploying the entire system."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Enhanced Resilience"}),": Failures in one skill don't affect the entire system."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Real-Time Updates"}),": SSE provides efficient streaming of updates to clients."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Simplified Testing"}),": Skills can be tested in isolation with mock dependencies."]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"challenges-and-considerations",children:"Challenges and Considerations"}),"\n",(0,i.jsx)(n.p,{children:"While this architecture offers significant advantages, there are challenges to consider:"}),"\n",(0,i.jsx)(n.h3,{id:"1-increased-operational-complexity",children:"1. Increased Operational Complexity"}),"\n",(0,i.jsx)(n.p,{children:"Managing multiple services instead of a monolith increases operational complexity. We addressed this with:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Comprehensive monitoring and logging"}),"\n",(0,i.jsx)(n.li,{children:"Automated deployment pipelines"}),"\n",(0,i.jsx)(n.li,{children:"Service discovery mechanisms"}),"\n",(0,i.jsx)(n.li,{children:"Centralized configuration management"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"2-consistency-across-skills",children:"2. Consistency Across Skills"}),"\n",(0,i.jsx)(n.p,{children:"Ensuring consistent behavior across independently developed skills requires:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Clear interface definitions"}),"\n",(0,i.jsx)(n.li,{children:"Shared utilities for common functions"}),"\n",(0,i.jsx)(n.li,{children:"Style guides and code standards"}),"\n",(0,i.jsx)(n.li,{children:"Regular cross-team reviews"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"3-error-handling",children:"3. Error Handling"}),"\n",(0,i.jsx)(n.p,{children:"Distributed systems need robust error handling:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Example of error handling in the agent core\nasync def execute_skill_with_fallback(self, primary_skill, fallback_skill, input_data):\n    """Execute a skill with fallback if it fails."""\n    try:\n        async for update in self.execute_skill(primary_skill, input_data):\n            yield update\n    except SkillExecutionError as e:\n        logger.error(f"Primary skill {primary_skill} failed: {str(e)}")\n        logger.info(f"Falling back to {fallback_skill}")\n        \n        # Notify the client of the fallback\n        yield {\n            "type": "status", \n            "data": {"status": f"Falling back to alternative approach"}\n        }\n        \n        # Execute fallback skill\n        async for update in self.execute_skill(fallback_skill, input_data):\n            yield update\n'})}),"\n",(0,i.jsx)(n.h3,{id:"4-state-management",children:"4. State Management"}),"\n",(0,i.jsx)(n.p,{children:"Handling state across distributed components requires careful design:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class SharedStateManager:\n    """Manages shared state across skills."""\n    \n    def __init__(self, redis_url):\n        self.redis = aioredis.from_url(redis_url)\n        \n    async def set_state(self, session_id, key, value, ttl=3600):\n        """Set a state value with expiration."""\n        state_key = f"session:{session_id}:{key}"\n        await self.redis.set(state_key, json.dumps(value), ex=ttl)\n        \n    async def get_state(self, session_id, key):\n        """Get a state value."""\n        state_key = f"session:{session_id}:{key}"\n        value = await self.redis.get(state_key)\n        return json.loads(value) if value else None\n'})}),"\n",(0,i.jsx)(n.h2,{id:"performance-and-monitoring",children:"Performance and Monitoring"}),"\n",(0,i.jsx)(n.p,{children:"With distributed components communicating via SSE, monitoring performance becomes crucial:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Example monitoring middleware for FastAPI\n@app.middleware("http")\nasync def add_performance_monitoring(request, call_next):\n    start_time = time.time()\n    \n    # Track request by type\n    metrics.increment(f"requests.{request.url.path}")\n    \n    # Execute the request\n    response = await call_next(request)\n    \n    # Record duration\n    duration = time.time() - start_time\n    metrics.timing(f"request_duration.{request.url.path}", duration)\n    \n    # Track response codes\n    metrics.increment(f"responses.{response.status_code}")\n    \n    return response\n'})}),"\n",(0,i.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,i.jsx)(n.p,{children:"The modular AI agent architecture with pluggable skills and SSE communication provides a scalable, flexible approach to building complex AI systems. By separating the core orchestration logic from specialized capabilities, we've created a system that can evolve more gracefully over time."}),"\n",(0,i.jsx)(n.p,{children:"This architecture has enabled us to:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"Scale development across multiple teams"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"Add new capabilities without disrupting existing ones"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"Provide real-time feedback to users during processing"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"Deploy and scale components independently"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"Choose the right technologies for each specific skill"})}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"While it introduces some additional complexity in terms of deployment and communication, the benefits far outweigh the costs for sophisticated AI agent systems with diverse capabilities."}),"\n",(0,i.jsx)(n.p,{children:"The combination of a strong orchestration core, independently deployable skills, and efficient SSE communication creates a foundation that can support increasingly advanced AI applications as they evolve."}),"\n",(0,i.jsx)(n.p,{children:"For teams building complex AI agents, we strongly recommend considering this modular, skill-based approach with real-time communication to create systems that can grow and adapt to changing requirements."})]})}function u(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},57384:e=>{e.exports=JSON.parse('{"permalink":"/blog/architecting-modular-ai-agents","source":"@site/blog/2025-04-05-modular-ai-agents/index.mdx","title":"Architecting Extensible AI Agents - A Modular Core with Pluggable Skills and SSE Communication","description":"Learn how to architect AI agent systems with a modular, skill-based approach and implement real-time communication using Server-Sent Events (SSE).","date":"2025-04-05T00:00:00.000Z","tags":[{"inline":false,"label":"AI Agents","permalink":"/blog/tags/tags/ai-agents","description":"Articles about AI agent systems and implementations"},{"inline":false,"label":"Microservices","permalink":"/blog/tags/tags/microservices","description":"Microservice architecture and implementations"},{"inline":false,"label":"SSE","permalink":"/blog/tags/tags/sse","description":"Server-Sent Events (SSE) implementation and usage"},{"inline":false,"label":"Architecture","permalink":"/blog/tags/tags/architecture","description":"System architecture and design patterns"},{"inline":false,"label":"Modular Design","permalink":"/blog/tags/tags/modular-design","description":"Modular software design approaches and patterns"}],"readingTime":11.995,"hasTruncateMarker":true,"authors":[{"name":"Jon Roosevelt","title":"Consultant","url":"https://jonroosevelt.com","page":{"permalink":"/blog/authors/all-jon-roosevelt-articles"},"socials":{"linkedin":"https://www.linkedin.com/in/jonroosevelt/","github":"https://github.com/RooseveltAdvisors"},"imageURL":"https://github.com/RooseveltAdvisors.png","key":"jon"}],"frontMatter":{"slug":"architecting-modular-ai-agents","title":"Architecting Extensible AI Agents - A Modular Core with Pluggable Skills and SSE Communication","authors":["jon"],"tags":["ai-agents","microservices","sse","architecture","modular-design"],"image":"/img/blog/2025-04-05-modular-ai-agents/hero-banner.jpg"},"unlisted":false,"prevItem":{"title":"Supporting SSE for Model Context Protocol (MCP) in Python - Introducing fastapi-mcp-client","permalink":"/blog/fastapi-mcp-client"},"nextItem":{"title":"Building Reliable AI Agents - Implementing Advanced Evaluation with Azure AI SDK and Custom APIM Integration","permalink":"/blog/azure-ai-evaluation-apim-integration"}}')}}]);